{"pages":[{"title":"about","text":"Who is Mozss? What do I want to do?A few years ago，在某次编程比赛中，三个长相奇异的菜鸟组队报名了这次比赛。他们的参赛目的是开发一款无敌好玩的安卓端AVG游戏。这款游戏的主角叫Mozss，名字灵感来自墨子号量子卫星，本着单词尽可能简短和发音相近的原则，他们商定出Mozss作为主角的名字。他们希望通过Mozss这个角色，向玩家们传递出只有敢于冒险，不断去碰撞更强的对手, 才能遇见更好的自己。这三个菜鸟们期待着Mozss的破壳而出之日，也期待着它仗剑走天涯的冒险之旅。但是，不幸的事情发生了，各种不可抗力的影响下，这款游戏最终走向了流产。就这样，Mozss结束了它的一生，Mozss的一生是悲催的，它本可以拥有精彩而充满美好的冒险之路，却夭折在几位“心狠手辣”的菜鸟手中，实在令人惋惜。这则寓言故事告诉我们：珍爱生命，远离菜鸟！！！ About Blog本博客用于记录工作和生活的点滴。 To EveryOne“世界上只有一种英雄主义,就是看清生活的真相之后依然热爱生活。” –罗曼·罗兰 ContactEmail : mozss1024@gmail.com微信: mozss1024 ThanksThanks for the technical support of Hexo &amp; Icarus.","link":"/about/index.html"}],"posts":[{"title":"hello","text":"","link":"/2018010162876/"},{"title":"about make","text":"","link":"/2019020162876/"},{"title":"产品人应该具备的能力","text":"能力模型 知识技能 市场维度: 对外商务沟通 产品维度: 行业认知 专业设计能力 运营维度 运营数据分析 营销与推广策略 危机预测与控制/预见性 客户导向 市场维度 市场/用户的调用与分析 产品维度 用户需求理解 产品规划 运营维度 渠道管理 领导力 项目管理 带人的能力/知识传递","link":"/202101227992/"},{"title":"产品人的工作流","text":"整个工作流: 市场分析, 竞品分析, 用户研究, 需求分析, 产品策划, 产品推进, 产品管理 市场分析 swot分析 商业模式(盈利模式) 流量变现模式 佣金分成模式 增值服务模式 收费服务模式 竞品分析 分析的等级 初级: 中级: 高级: 分析的类型 核心竞品: 重要竞品: 潜在竞品: 分析的维度 市场: 资源: 数据: 月活, UV, 营业收入 运营: 活动时间, 活动成本, 内容建设, 转化率 功能: 核心功能, 非核心功能 用户: 画像, 行为… UE, UI: 流程, 主色调 获取信息 公开信息: google, 财报, 36kr, 微信… 半公开信息: 亲自体验, excel, 爬虫… 内幕信息: 沙盘推演, 人际情报, 黑客… 用户研究 定性研究 用户访谈 情景访谈 定量研究 问卷调查 数据分析 A/B测试 需求分析 需求来源 需求类型 需求优先级分析 “用户-使用频率”四象限 “见效快慢-开发难度”四象限 产品策划 业务流程图 确定范围 确定要素 梳理呈现 评审确认 页面流程图 找出所有的页面 用有向线条关联 增加条件判断 功能结构图 提炼主要功能模块 细化功能粒度 信息结构图 将产品的全部信息进行罗列, 建议使用脑图 就产品的信息进行梳理使其结构化 原型图 产品推进产品管理 产品发布 非技术手段: 推送; 公告 技术手段: A/B测试; 平滑部署; 增量分布 版本管理","link":"/2021032544066/"},{"title":"关于产品的思考","text":"产品是什么?“让用户花最少的成本满足需求”, 用户体验是个完整过程 用户体验是因人而异的 用户体验是因时而变的 … 回答出”产品是什么?”有难度的, 但好的产品能让绝大多数的用户”感受到它的好” “美女是什么? vs “好的产品是什么?”百度百科说美女是”容貌姣好、仪态优雅的女子”, 其实关键并不是”容貌姣好、仪态优雅”这8个字的评价. 百度百科说好的产品是”需求上有用的，技术上可实现的，商业上可持续的”, 关键也不在于”需求, 技术, 商业”这三个维度上的评价. “美女”和”好的产品”本身是无需要评价的, 只不过它们恰到好处解决了”我们遇到的问题”, 以”解决我们的问题”为核心, 再此基础上整合了一些科学, 商业, 道德的标准和要求, 然后创立了一套自带评价体系的系统. 产品需要的知识?产品经理, 项目经理, 程序员看待”产品”的视角都是单维的, 缺少大局观. 而”产品”本身就是跨学科的, 设计并实现一个”产品”并非易事, 需要科学的技术去指导. 百度搜索产品经理所需要的知识, 你会发现, 涉及到方方面面的知识, 其实都是比较微观的, 比较具体的. 本质上, 我认为产品经理需要的是”以产品本身为原点, 可以系统化地推进设计与实现出产品所需要的一套方法论和行为准则”.","link":"/202105113/"},{"title":"关于敏捷的思考","text":"为什么会有敏捷? 确定型工作 vs 不确定性工作 确定型工作: 范围前期确定, 不易变更 项目工作可以按计划进行 产品一次性交付 团队成员以动手执行为主 不确定型工作: 范围难以事先确定, 走一步看一步 计划赶不上变化 产品可多次交付 团队成员既要动手, 又要动脑 两种工作类型的特点 确定型工作: 像发射火箭 项目开始前收集好需求, 做好详细计划 项目过程中严格按照计划执行, 控制变更 项目后期测试产品, 请求客户验收 不确定型工作: 像发射巡航导弹 项目开始前很难收集完整的需求, 无法进行特别详细的计划 项目过程中临时增加的内容较多, 变更频繁 项目过程中客户希望尽早看到产品并体验, 而不是项目后期才看到产品 两种工作类型所采用的模型(框架): 两种工作方式的效果对比:","link":"/2021072257886/"},{"title":"MySQL规范","text":"MySQL 使用规范索引规范 在表中使用索引来加速数据查询和服务，但不要过度使用，因为索引需要占用磁盘空间和计算资源。 选择唯一索引或组合索引来提高查询效率和减少冗余数据。在执行操作时注意索引的效率和复杂性，并避免竞争条件。 对于数据类型为字符串的列，应该在其前面定义一个前缀索引，避免不必要的空间占用和计算开销。 SQL 规范 对于任何 SQL 查询操作，都应该使用合适的语法和正确的顺序来避免错误和提高执行效率。 对于 SELECT 语句，在使用通配符时应该尽量避免使用 SELECT *，而是在需要的列上明确指明。 在使用计数函数 COUNT() 时，应该使用 COUNT(*) 而不是 COUNT(column) 来避免空值的统计问题。 对于 UPDATE 和 DELETE 操作，在对数据表做出重大更改之前应该先备份原有数据，以防止被错误操作所破坏。 命名规范 对于数据库和表，应该使用下划线作为单词之间的分隔符，如 “my_database” 和 “my_table”。 对于字段名，应该使用下划线或者驼峰命名方式，如 “my_field_name” 或 “myFieldName”。 对于存储过程或视图，应该使用有意义的名称来描述它们的功能和用途，以方便管理和维护。 对于索引，应该使用有意义的名称来反映它们的内容和作用，避免混淆和重复。 以上是 MySQL 使用规范的一些要点，遵循这些规范可以提高数据库的可读性、可维护性和性能。","link":"/2019031162876/"},{"title":"MySQL调优思路","text":"MySQL调优思路MySQL是一种开源、关系型数据库。调优MySQL是提高系统性能的一个关键部分。本文将介绍一些常见的MySQL调优思路和技巧。 确定瓶颈要调优MySQL，首先需要确定瓶颈所在。常见的瓶颈包括CPU、内存、磁盘和网络。了解这些瓶颈所在，可以有针对性地优化MySQL。 选择合适的存储引擎MySQL支持多种不同的存储引擎。不同的存储引擎有不同的优势和劣势。InnoDB是MySQL的默认存储引擎，它适用于事务处理。MyISAM是另一种常见的存储引擎，适用于读取频繁、写入不频繁的应用。选择合适的存储引擎可以提高MySQL的性能。 优化查询语句优化查询语句可以提高MySQL的性能。在设计查询语句时，需要考虑以下几个方面： 避免使用SELECT * 遵循查询的原则 避免使用子查询 避免使用表连接（尤其是多表连接） 使用索引进行查询 设置合适的缓冲区大小适当地设置缓冲区大小可以提高MySQL的性能。MySQL中有一些缓冲区，如查询缓存、表缓存、连接缓存和排序缓存等。适当地设置这些缓冲区的大小，可以避免频繁访问磁盘，从而提高MySQL的性能。 使用分区表如果有大量的数据需要操作，使用分区表可以提高MySQL的性能。分区表将数据分成多个部分，每个部分可以单独进行操作，从而提高操作效率。 使用主从复制使用主从复制可以提高MySQL的性能和可用性。主从复制是将主数据库中的数据复制到从数据库中，从数据库可以用于读取操作，从而减轻主数据库的负载。 定期维护数据库定期进行数据库的维护可以提高MySQL的性能。维护工作包括备份数据库、优化数据库结构、删除不需要的数据和优化数据库配置等。 以上是MySQL调优的一些常见思路和技巧。通过合理调优MySQL，可以提高性能和可用性，从而更好地满足业务需求。","link":"/2019042162876/"},{"title":"JDBC驱动","text":"驱动Mysql的驱动jar, 默认有两个功能, 主从分离和HA.如果你只是需要一个主从分离, failover功能, 不要sharding, 一个驱动就够,也就不需要引入中间层. 有个Replication协议, 在5.1.x版本之后,增加了这些功能, 以用来支持”multi-host”集群拓扑的访问范式. 这个功能是在驱动层实现的. jdbc连接如下 1jdbc:mysql://127.0.0.1:3306/test?characterEncoding=UTF-8 通过协议改造后的jdbc连接如下 1jdbc:mysql:replication://127.0.0.1:3306,127.0.0.1:3307,127.0.0.1:3308/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=false&amp;loadBalanceStrategy=random 协议后的第一个连接, 表示主库Master后面一堆连接,表示从库Slave, 当然可以有多个当你把Master的连接也放在后面的一堆里面, 那么它也拥有”读库”的属性了后面有一堆参数, 来控制这所有连接, 到底要如何相处 代码层对于Spring来说, 就可以使用Transaction注解来控制这个属性, 一个事务不可能跨两个连接, 所以是读还是写, 由最高层决定. 12345public interface UserManager{ public UserDO get(int id); public void insert(UserDo user); public void update(int id);} 12345678910@Componentpublic class UserManagerImpl implements UserManager{ @Autowired private UserDao userDao; //... @Transactional(readOnly = false, propagation=Propagation.REQUIRED) public void insert(UserDO user){ this.userDao.insert(user); }} 参数 readFromMasterWhenNoSlaves当所有的salve死掉后, 此参数用来控制主库师傅参与读 loadBanlanceStrategy策略用来指定从库的轮询规则. 有轮询, 也有权重, 也可用指定具体策略实现. 当你维护或迁移某个实例时, 先置空流量, 这回非常有用. 或许, 你会给某个DB一个预热的可能. allowMasterDownConnections如果主机宕机,当连接池获取新的连接时会失败. retriesAllDown 当所有的hosts都无法连接时重试的最大次数（依次循环重试）,默认为120. autoReconnect 实例既然有下线、就有上线。上线以后要能够继续服务，此参数用来控制断线情况下自动重连而不抛出异常.","link":"/2019030162876/"},{"title":"mysql的分库分表实践","text":"MySQL分库分表实践概述MySQL是目前应用最广泛的关系型数据库之一，随着数据量的增长和系统访问的增加，单一的MySQL实例可能无法承受大量的访问和数据存储压力，分库分表成为MySQL扩容的一个最佳实践方案，本文将介绍如何实现MySQL分库分表。 分库分表架构分库分表架构本质上就是将一个大的数据库拆分为多个数据库实例，然后将每个实例再拆分为多个数据表，最后将访问各个表的业务逻辑分别分配到多个数据库实例上。分库分表的目的在于提高MySQL的性能和扩展能力，降低单机MySQL对系统的压力。 分库分表的最终目的是能够处理海量数据的查询请求，因此我们必须保证分库分表的策略是正确和有效的。一个好的分库分表策略不仅能够大幅度提高MySQL的性能，还能在一定程度上提高MySQL的可用性和可靠性。 常见的MySQL分库分表策略包括： 垂直拆分：将数据库中的不同表按照逻辑功能拆分为不同的数据库实例，这种方法一般用于不同表之间没有关联关系或者关联关系不太紧密的情况。 水平拆分：将数据库中的同一张表按照一定的规则拆分为多个表，每个表存储一部分数据，这种方法一般用于数据存储量非常大的情况。 分区：将同一张表按照一定的规则拆分为若干个子表，每个子表存储一部分数据，这种方法一般用于数据存储量非常大并且查询请求比较频繁的情况。 实践步骤步骤一：确定业务需求和分库分表策略在Java代码中使用分库分表的方式有很多，比如使用Sharding-JDBC、MyCAT等中间件，分别在代码层面和数据层面实现分库分表的功能。在使用这些中间件之前，我们需要先确定业务需求和分库分表的策略，包括数据库的切分规则、表的切分规则、数据量以及各种数据操作的约束等。 步骤二：设计分库分表方案在确定业务需求和分库分表的策略之后，我们需要设计分库分表的方案，包括如何切分数据库、如何切分表、如何在各个数据库实例之间实现数据的同步等。 步骤三：实现数据源的配置和使用在设计好分库分表方案之后，我们需要在代码中实现数据源的配置和使用。在Java中常使用spring-jdbc和spring-mybatis等框架对分库分表进行实现，通过在配置文件中配置数据源和MyBatis的Mapper接口等信息，我们可以轻松地使用分表查询和分表插入等操作。 步骤四：测试和优化在实现分库分表系统之后，我们需要对系统进行测试和优化。针对不同业务场景下的数据操作，我们需要评估查询效率、数据写入效率、系统稳定性以及数据一致性等方面的性能。 总结MySQL分库分表是提高系统性能和扩展能力的一个最佳方案，设计好分库分表的方案并正确地应用在实际场景中，可以极大地提高系统的性能和扩展能力。希望本文能够为大家使用MySQL分库分表提供一些实践经验和思路，让大家更好地应用MySQL分库分表技术。","link":"/2019040162876/"},{"title":"linux进程调度算法","text":"当发生下面几种情况的时候会调用短程调度器，然后就看下次执行那个进程啦 时钟中断 I/O中断 操作系统调用 信号（如信号量） 进程调度算法： 先来先服务（FCFS） 短作业优先（SPN） 最短剩余时间（SRT） 时间片轮转 最高响应比优先 公平共享调度 先来先服务 就和名字一样，哪个进程先来就先获得处理器时间，，用一个队列暂存等待处理器的进程，优点是实现简单（太简单了吧喂），缺点，遇到那种又臭又长的进程就很不爽了，好比食堂打饭，前面的人不买一直问，后面的人一直排队，那么后面的人就怎么了呢？后面的人就饥饿！同时如果现在有一个马上就要饿死的人急需吃饭，这就很尴尬了（紧急的进程无法处理，优先级高的进程处于饥饿状态），所以有了优先级队列的先来先服务算法，这样也不是很好，因为总有又臭又长的进程，排队是谁都不乐意的吧，而且处理器时间就不公平了。 短作业优先 因为先来先服务不好，所以有了短作业优先，通过设置执行时间短的进程作业的优先级为高来实现，也很简单粗暴，就是说进程时间越短就越先执行，看着是比较好了，不浪费时间了，但是有没有想过长进程的感受，来了一群短的进程，然后一直来短进程，这是要饿死长进程的节奏，人家长有错么？如果是可抢占的方式（见最短剩余时间版本），就更惨了，只要来了更短的就别想好好执行了。。。 最短剩余时间 就是刚才说的短作业优先的抢占版本，说过他的缺点了，当前执行的进程还剩10个时间单位，但是一直来了一群只要2个时间单位就跑完的进程，那当前的进程就会被抢占，然后含恨饿死。。 时间片轮转 既然上面几种算法都有可能出现饥饿进程，那么我就干脆让每个进程都执行那么一会，这样不就比较公平了？每个进程都有机会在处理器上跑，看起来很和谐，但是还是没有解决优先级的问题，优先级不好控制，比如有什么紧急的进程需要立即执行，就不好办了。而且每个进程的具体情况也是不一样的，比如有I/O消耗型进程，和处理器消耗型进程，在同样的事件片里真正占用处理器的时间是不一样的，而我们是真正占用处理器的时间希望能一样的，这样就公平了嘛。这样看来，时间片轮转也是有缺点的。 最高响应比优先 什么是响应比？看一下这个公式：R=(w+s)/s，其中R是响应比，w是等待处理器的时间，s是期待的服务时间，简单的来说响应比就是，进程从加入等待队列开始一直到执行完毕经历的时间除以进程使用处理器的时间，这个响应比比较高的就证明该进程等待比较久了，它估计会很饿，先让它吃！ 公平共享调度 Linux系统中普通进程使用的调度方法就是公平共享调度的一个实例，被称作完全公平调度算法（CFS），虽然一定不可能公平。。。详情参照我的另一篇博客。。传送门召唤！！：http://www.cnblogs.com/lenomirei/p/5516872.html Linux系统中的进程调度方案 Linux在进行进程调度的时候把进程分为两种：1.普通进程；2.实时进程 实时进程的优先级永远比普通进程的优先级高，也就是说实时进程只要来了就可以抢占普通进程，而且还抓住处理器就不撒手，直到所有的实时进程都执行完毕，才会把处理器让出来给普通进程使用 之前也说了，普通进程的调度采用的是完全公平调度（CFS）对应的是SCHED_NORMAL 而实时进程采用的调度方法就比较简单粗暴了，Linux提供了两种实时调度策略：SCHED_FIFO和SCHED_RR。 SCHED_FIFO：简单的先入先出的调度算法，不使用时间片，只可能被更高优先级的FIFO或者SCHED_RR抢占 SCHED_RR：时间片轮转的方式，优先级比SCHED_FIFO还要高，可以抢占SCHED_FIFO 实时进程的调度没有实时优先级这一说法，采用的是静态优先级，一开始定好优先级之后就不会改变了。","link":"/20190118cc71bb07/"},{"title":"redis避坑指南","text":"使用 Redis 避坑指南Redis 是一种高性能的键值存储数据库，它已经成为了许多应用的核心组件。然而，使用 Redis 的过程中也经常会遇到一些问题。本文将介绍一些避坑指南，帮助你更好地使用 Redis。 一、使用连接池在操作 Redis 时，与数据库建立连接是一个比较费时的过程。如果每一次操作 Redis 都要建立一个新的连接，那么就会严重降低系统的性能。因此，在使用 Redis 时建议使用连接池。连接池可以提供连接的复用，避免了频繁建立连接的过程。 二、选择合适的数据结构Redis 提供了多种不同的数据结构，如字符串、哈希、列表、集合和有序集合等。在使用 Redis 时，需要根据实际情况选择合适的数据结构。例如，如果要对一个计数器进行操作，就可以选择字符串类型。如果要对一个具有字段的对象进行存储，就可以选择哈希类型。 三、合理设置超时时间在使用 Redis 时，需要设置合理的超时时间。超时时间指的是在一段时间内没有访问就会自动释放资源。如果设置的时间太短，可能会导致频繁的连接建立，从而影响系统性能。如果设置的时间过长，可能会浪费资源和内存。因此，需要根据实际情况设置合理的超时时间。 四、避免使用 keys 命令在 Redis 中，使用 keys 命令可以列出所有的键值。虽然这个命令非常方便，但是它会扫描整个数据库，会造成较大的性能损失。为了避免这个问题，建议使用更具体的命令来操作数据库。 五、使用 Pipeline 提高性能在 Redis 中，可以使用 Pipeline 命令来批量处理请求。Pipeline 可以将多个命令打包发送到 Redis 服务器，从而提高操作性能。如果需要处理大量的数据，建议使用 Pipeline 命令。 六、定期清理过期的键值在 Redis 中，可以设置键值对的过期时间。如果过期时间到期后，没有对该键值对进行任何操作，那么该键值对就会被自动删除。因此，定期清理过期的键值对非常重要，可以避免内存泄漏和资源浪费等问题。 七、使用 Lua 脚本优化性能在 Redis 中，可以使用 Lua 脚本来实现一些比较复杂的操作。由于 Lua 脚本是原子操作，可以避免竞争条件。如果需要进行比较复杂的操作，建议使用 Lua 脚本进行操作。 八、使用 Redis Sentinel 进行高可用性部署在 Redis 集群中，有一些节点可能会故障，如果无法及时处理，就会影响整个集群的稳定性和可用性。因此，建议使用 Redis Sentinel 进行高可用性部署。Redis Sentinel 可以监控 Redis 节点的状态，并在节点发生故障时自动执行故障转移操作，提高了集群的可用性和稳定性。 以上就是使用 Redis 避坑的一些指南。当然，使用 Redis 还有更多的细节需要注意，需要在实践和经验中不断修正和优化。","link":"/2019071162876/"},{"title":"Redis vs MySQL","text":"Redis与MySQL对比Redis和MySQL是两个常用的开源数据库，虽然它们的使用场景不同，但是它们也有许多相似之处。在这篇文章中，我们将对比Redis和MySQL的一些关键区别，并探究它们的优劣势。 Redis和MySQL的区别 数据结构 Redis的数据可以存储在不同的数据结构中，例如：strings，hashes，lists，sets和sorted sets。与此不同，MySQL是一个传统的关系型数据库，数据按行列存储在表格中，使用SQL进行操作。 数据查询 由于Redis的数据存储方式，它通常被用于高速读写，可以快速访问单个对象或数据集合。Redis支持使用key-value的方式操作数据，可以高效地进行数据查询、写入和删除等操作。虽然MySQL也支持高速读写，但它通常被用于大型数据存储和复杂查询。 数据持久化 Redis的默认配置是将数据保存在内存中。虽然这使得它可以快速访问和处理数据，但也导致了数据易丢失。为了防止数据丢失，Redis提供了数据持久化机制，可以将数据写入磁盘中，以保护数据。而MySQL默认情况下则将数据保存在磁盘中，并提供了多种数据备份和恢复工具。 扩展性 Redis可以通过集群方式扩展，可以实现无限的水平扩展，在处理高流量负载时表现出色。MySQL也可以通过集群方式扩展，但它有一些限制，例如水平扩展仅限于读取操作，写操作仍然受限于单节点的机器性能，无法有效地满足高流量负载需求。 Redis与MySQL的优缺点Redis的优点 高速读写：由于Redis将数据存储在内存中，它的读写速度非常快，可以轻松地操作大量数据。 数据结构丰富：Redis的数据结构非常灵活，支持不同的数据类型，可以方便地对特定数据进行处理。 可扩展：Redis通过集群方式可以轻松地实现伸缩性，在处理高流量负载时表现出色。 Redis的缺点 数据容易丢失：由于Redis默认将数据存储在内存中，如果服务器发生故障或出现断电的情况下，数据将会丢失。 基于内存存储：Redis的内存存储方式意味着存储容量与服务器内存容量有关，存储容量有比较严格的限制。 MySQL的优点 数据安全：MySQL提供了多种数据备份和恢复工具，可以保证数据安全。 支持复杂查询：MySQL是一个丰富的关系型数据库管理系统，可以轻易地处理复杂的数据查询和管理操作。 成熟的生态系统：MySQL早已成熟，有着完善的生态系统和用户社区支持。 MySQL的缺点 数据读写速度较慢：相比Redis，MySQL的读写速度较慢，无法有效地处理大量数据请求。 限制扩展：MySQL的扩展方式较为受限，无法轻易地伸缩性。 结论Redis和MySQL都是非常流行的数据库，各自有着优缺点。选择哪个数据库取决于您要处理的是什么类型的数据、负载容量和安全需求。如果您的业务需要处理高并发读写请求，那么Redis可能更适合您。如果您的业务处理需要更多的查询和数据操作，那么MySQL可能是您的不二之选。","link":"/2019081162876/"},{"title":"redis正确的使用姿势","text":"如何提升 Redis 实践？Redis 是一个开源的高性能 NoSQL 数据库，因其快速、可扩展和强大的特点而备受青睐。在实际应用中，如何提升 Redis 实践的效率和性能呢？以下是几条建议： 1. 选择适当的数据结构Redis 支持多种数据结构，包括字符串、哈希、列表、集合和有序集合。在使用时，应根据实际需求选择适当的数据结构，以最大限度地利用 Redis 的性能优势。例如，在计数器场景中，使用 INCR 命令递增一个存储在 Redis 字符串中的计数器变量比使用哈希或列表结构更快。 2. 设计合理的数据模型在设计 Redis 数据模型时，应遵循以下原则：简单易懂、易于维护和扩展、充分利用 Redis 特性、避免重复存储和冗余数据。例如，在一个社交网站应用中，可以使用 Redis 哈希表存储用户信息，使用列表存储用户关注的人或被关注的人列表，使用有序集合存储用户的文章或评论。 3. 避免频繁的网络通信Redis 是单线程模型的数据库，网络通信成为 Redis 操作的瓶颈。因此，应避免频繁地执行网络通信操作。例如，在读取多个键的值时，应使用 Redis MGET 命令一次性地完成，而不是多次执行 GET 命令。另外，可以通过将相邻的读取操作合并为一个操作，从而减少网络通信次数。 4. 合理设置 Redis 配置Redis 的性能受到多个因素的影响，如内存大小、最大连接数、持久化方式等。在实际应用中，应根据实际情况对 Redis 的配置进行优化和调整。例如，可以设置合适数量的连接池，以保证 Redis 连接的有效性和稳定性；可以选择 RDB 持久化机制或 AOF 持久化机制来适应不同的场景。 5. 优化 Redis 命令的使用在使用 Redis 命令时，应注意一些优化技巧。例如，使用 EXPIRE 命令可以添加到 Redis 中的键中设置过期时间，以减轻内存负担；使用 SCAN 命令可以遍历大量的数据，而不会阻塞 Redis 服务器；使用 Pipeline 可以将多个命令合并成一个请求，提高网络通信效率。 综上所述，通过选择适当的数据结构、设计合理的数据模型、避免频繁的网络通信、合理设置 Redis 配置和优化 Redis 命令的使用，可以提高 Redis 实践的效率和性能，为应用带来更好的体验和收益。","link":"/2019070562876/"},{"title":"服务化治理脚本----查找cpu利用率最高的线程","text":"show-busiest-java-threads命令格式:./show-busiest-java-threads -p 进程号 -c 显示条数./show-busiest-java-threads-h 1234567891011#!/bin/bash# @Function# Find out the most cup consumed threads of java, and print the stack trace of these threads.## @Usage# $ ./show-busiest-java-thread -h #","link":"/2022050155140/"},{"title":"Nginx常用功能","text":"NGINX 常用功能NGINX 是一款高性能的 Web 服务器和反向代理服务器，常用于构建高性能和可伸缩性的 Web 应用程序。除了作为 Web 服务器和反向代理服务器之外，NGINX 还可以实现许多其他功能。在本文中，我们将介绍 NGINX 的一些常用功能。 静态文件服务NGINX 可以提供静态文件服务，通过 HTTP 协议将本地存储的文件发送到客户端。其实现非常简单，只需要在 NGINX 的配置文件中增加一条 location 指令即可： 123456789server { listen 80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; }} 在上述配置中，NGINX 将会监听 80 端口，在根 / 路径下提供静态文件服务。所有访问该路径下的文件请求都将被定位到 /usr/share/nginx/html 文件夹下。 反向代理NGINX 可以作为反向代理服务器，转发来自客户端的请求到后端的多个 Web 服务器。在这种情况下，NGINX 将作为客户端和后端服务器之间的“中间人”，负责转发请求和响应。其实现也非常简单，只需要在 NGINX 的配置文件中增加一条 server 指令即可： 12345678910111213141516171819server { listen 80; server_name example.com; location / { proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # ...}upstream backend { server backend1.example.com; server backend2.example.com;} 在上述配置中，NGINX 将会监听 80 端口，在 example.com 的根路径下转发所有请求到名为 backend 的后端服务器。后端服务器的地址应该在 upstream 块中定义。同时，NGINX 还可以设置一些代理相关的头部信息。 负载均衡NGINX 可以作为负载均衡器，将来自客户端的请求分发到多个后端服务器，并尽可能地平均负载。在这种情况下，NGINX 将作为客户端和后端服务器之间的“中间人”，负责分发请求和响应。其实现也非常简单，只需要在 NGINX 的配置文件中增加一条 upstream 指令即可： 1234567891011121314upstream backend { server backend1.example.com; server backend2.example.com; server backend3.example.com;}server { listen 80; location / { proxy_pass http://backend; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; }} 在上述配置中，NGINX 将会监听 80 端口，并将来自客户端的请求分发到三个名为 backend1.example.com、backend2.example.com 和 backend3.example.com 的后端服务器上。同时，NGINX 还可以设置一些负载均衡相关的选项。 URL 重写NGINX 可以重写客户端请求的 URL，将原始 URL 转换为另一个 URL 并发送到后端服务器。这种功能可用于隐藏后端服务器的实际位置、根据请求内容转发到不同的后端服务器、或调整请求的结构等。其实现需要在 NGINX 的配置文件中增加一条 location 指令： 123location / { rewrite ^/(.*)$ /index.php?q=$1 last;} 在上述配置中，NGINX 将会重写客户端请求的 URL，在路径 / 下将所有请求重写为 /index.php?q=$1 的格式。其中，$1 是原始 URL 的捕获组。 SSL 终端NGINX 可以作为 SSL 终端，与客户端建立 SSL 连接，然后解密和加密所有传输的数据。其实现需要在 NGINX 的配置文件中增加一条 server 指令： 1234567891011121314server { listen 443 ssl; server_name example.com; ssl_certificate /path/to/certificate.pem; ssl_certificate_key /path/to/certificate_key.pem; location / { proxy_pass http://backend; proxy_redirect off; } # ...} 在上述配置中，NGINX 将会监听 443 端口，并在建立 SSL 连接后将请求分发到名为 backend 的后端服务器上。同时，NGINX 还需要指定 SSL 证书和私钥。 WebSocket 支持NGINX 可以支持 WebSocket 协议，允许客户端与服务器之间建立双向的实时通信连接。其实现需要在 NGINX 的配置文件中增加一条 location 指令： 1234567location /ws { proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;;} 在上述配置中，NGINX 将会将路径 /ws 下的所有 WebSocket 请求转发到名为 backend 的后端服务器上。同时，NGINX 还需要设置一些代理相关的头部信息。 缓存NGINX 可以缓存某些请求的响应，避免反复从后端服务器重新获取响应。其实现需要在 NGINX 的配置文件中增加一条 proxy_cache_path 指令和一条 proxy_cache 指令： 123456789101112131415proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m;server { # ... location / { proxy_cache_bypass $http_pragma; proxy_cache_revalidate on; proxy_cache_key &quot;$scheme$request_method$host$request_uri&quot;; proxy_cache_valid 200 10m; proxy_cache_valid 404 1m; proxy_pass http://backend; }} 在上述配置中，NGINX 将会缓存名为 my_cache 的反向代理响应。所有请求的缓存将会被存储在 /var/cache/nginx 目录下。同时，NGINX 还可以设置一些缓存相关的选项。 总结在本文中，我们介绍了 NGINX 的一些常用功能，包括静态文件服务、反向代理、负载均衡、URL 重写、SSL 终端、WebSocket 支持和缓存。这些功能可以用于构建高性能和可伸缩性的 Web对不起啦，脑子转不过啦，暂时无法回答的您的问题，请稍后重试！！","link":"/2019050162876/"},{"title":"服务化治理脚本----jar包的包名和类名中查找某一关键字","text":"find-in-jar此脚本用于在jar包的包名和类名中查找某一关键字, 并高亮显示匹配的包名, 类名和路径,多用于定位java.lang.NoClassDefFoundError和java.lang.ClassNotFoundException的问题, 以及类版本重复或冲突的问题. 命令格式:find-in-jar 关键字 类名根路径 1234567891011#!/bin/bashfind . -name &quot;*.jar&quot; &gt; /tmp/find_in_jar_tempwhile read linedo if unzip -l $line | grep $1 &amp;&gt; /tmp/find_in_jar_temp_second then echo $line | sed 's#\\(.*\\)#\\x1b[1;31m\\1\\x1b[00m#' cat /tmp/find_in_jar_temp_second fi done &lt; /tmp/find_in_jar_temp","link":"/2022050257828/"},{"title":"服务化治理脚本----把线上的二进制包拉下来并查找特定的关键字来定位问题","text":"grep-in-jar在jar包中进行二进制内容查找, 通常会解决线上出现的一些”不可思议”的问题, 例如: 某些功能没有生效, 某些日志没有打印, 通常是线上工具或上线过程中出现了问题, 可以把线上的二进制包拉下来并查找特定的关键字来定位问题. 命令格式:grep-in-jar 关键字 路径 12345678910111213141516171819#!/bin/bash### grep text inside jar contentif [ $# -lt 2 ]; then echo 'Usage : grep-in-jar text path' exti 1;fiLOOK_FOR=$1LOOK_FOR='echo ${LOOK_FOR//\\./\\/}'folder=$2echo &quot;find '$LOOK_FOR' in $folder&quot;for i in 'find $2 -name &quot;*jar&quot;'do unzip -p $i | grep &quot;$LOOK_FOR&quot; &gt; /dev/null if [ $? = 0 ]; then echo &quot;==&gt; Found \\ &quot;$LOOK_FOR\\&quot; in $i&quot; fidone","link":"/2022060111307/"},{"title":"使用nginx需要注意的问题","text":"避免使用Nginx时陷入坑Nginx是一个高性能的Web服务器和反向代理服务器，经常用于部署Web应用程序和服务。然而，当使用Nginx时，不遵循最佳实践和常见的错误可能会导致一些问题，本文将介绍一些关于使用Nginx需要避免的坑。 不要滥用正则表达式在Nginx配置中，正则表达式是非常重要的组成部分，但是如果在配置文件中滥用正则表达式可能会导致服务性能下降，甚至引发诸如内存泄漏、内存溢出和不必要的CPU使用等问题。在配置文件中避免使用过于复杂的正则表达式，尝试使用更简单的规则来实现相同的结果。 慎重使用rewrite指令rewrite指令用于将URL重定向到其他URL，但是当使用rewrite时，可能会发生以下问题： 内存泄漏：当Nginx服务器上有大量的URL被重定向时，rewrite指令可能导致内存泄漏，这可能会导致服务器崩溃或需要重启服务器以释放内存。 安全问题：rewrite指令可以允许使用者通过URL来操作服务器。如果没有正确地配置rewrite规则，则可能允许攻击者通过修改请求URL来获取敏感数据或执行恶意代码。 性能：rewrite指令可能会降低Web服务器的性能，因为每次重定向都需要执行一些额外的操作。 因此，当使用rewrite指令时，需要慎重考虑它的启用条件和使用方式。 配置文件语法错误处理Nginx的配置文件语法相对简单，但是在错误的配置文件中使用无效的语法可能会导致服务器崩溃。为了避免这种情况的发生，应该保存原始配置文件并将更改应用到复制的文件中，以确保在配置过程中保留备份。并且，在做任何更改之前，应该测试和验证配置文件，以确保没有语法错误。 不要在配置文件中硬编码密钥硬编码密钥可能会导致安全漏洞，因为如果密钥泄露，攻击者可能就能够获得访问敏感信息的权限。为了避免此类问题，应该使用环境变量、密钥管理系统或其他安全的方式将密钥注入配置文件中。 应该启用keepalive连接keepalive连接可以降低网络延迟，减少TCP连接时间，并提高性能。为了从keepalive连接中获得利益，建议设置一个适当的超时时间，以确保不会浪费服务器资源。 总结以上是在使用Nginx时需要避免的坑。虽然Nginx是一个高性能的Web服务器和反向代理服务器，但是需要遵循最佳实践和常见的错误可能会导致一些问题。在配置文件中避免使用过于复杂的正则表达式、慎重使用rewrite指令、配置文件语法错误处理、不要在配置文件中硬编码密钥以及启用keepalive连接是最佳实践。","link":"/2019052162876/"},{"title":"责任链","text":"人类的责任感和责任心是非常重要的，有时候我们需要把一些任务交给另外一个人完成，但是我们不能确定是哪一个人能够承担这个任务。那么，我们就需要使用“责任链模式”（Chain of Responsibility Pattern）来解决这个问题。 责任链模式是一种行为型模式，它为多个对象（接收者）提供了解决请求的方法，但是客户端只需要知道第一个对象，它会自动把请求传递给下一个对象，直到有一个对象能够处理请求为止。这个过程就像是一条链，所以称之为责任链模式。 我们来看一个例子，假设我们需要处理用户在网站上的注册请求。首先，我们需要验证用户的用户名和密码是否符合要求。如果通过验证，就要提交给下一个处理者来检查用户的邮箱和电话号码是否正确。如果还是通过了，就会提交给下一个处理者检查用户的公司和职位信息是否完整。最后，如果全部通过了，就把用户信息保存到数据库中。 下面是责任链模式的Java代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// 抽象处理者，定义处理请求的接口public abstract class Handler { protected Handler successor; // 维持一个后继对象 public void setSuccessor(Handler successor) { this.successor = successor; } public abstract void handleRequest(User user); // 处理请求的抽象方法}// 具体处理者1，处理用户名和密码验证请求public class UserNameAndPasswordHandler extends Handler { @Override public void handleRequest(User user) { if (user.getName() != null &amp;&amp; user.getPassword() != null) { System.out.println(&quot;用户名和密码验证通过&quot;); if (successor != null) { successor.handleRequest(user); // 传递给下一个处理者 } } else { System.out.println(&quot;用户名或密码未填写&quot;); } }}// 具体处理者2，处理用户邮箱和电话验证请求public class EmailAndPhoneHandler extends Handler { @Override public void handleRequest(User user) { if (user.getEmail() != null &amp;&amp; user.getPhone() != null) { System.out.println(&quot;用户邮箱和电话验证通过&quot;); if (successor != null) { successor.handleRequest(user); // 传递给下一个处理者 } } else { System.out.println(&quot;用户邮箱或电话未填写&quot;); } }}// 具体处理者3，处理用户公司和职位信息验证请求public class CompanyAndPositionHandler extends Handler { @Override public void handleRequest(User user) { if (user.getCompany() != null &amp;&amp; user.getPosition() != null) { System.out.println(&quot;用户公司和职位信息验证通过&quot;); // 不需要传递给下一个处理者了，直接保存到数据库 System.out.println(&quot;用户信息已保存到数据库&quot;); } else { System.out.println(&quot;用户公司或职位信息未填写&quot;); } }}// 用户类public class User { private String name; private String password; private String email; private String phone; private String company; private String position; // 省略getter和setter方法}// 客户端类public class Client { public static void main(String[] args) { // 创建处理者对象 Handler handler1 = new UserNameAndPasswordHandler(); Handler handler2 = new EmailAndPhoneHandler(); Handler handler3 = new CompanyAndPositionHandler(); // 构建责任链 handler1.setSuccessor(handler2); handler2.setSuccessor(handler3); // 创建用户对象 User user = new User(); user.setName(&quot;Tom&quot;); user.setPassword(&quot;123456&quot;); user.setEmail(&quot;tom@abc.com&quot;); user.setPhone(&quot;12345678901&quot;); user.setCompany(&quot;ABC公司&quot;); user.setPosition(&quot;程序员&quot;); // 处理请求 handler1.handleRequest(user); }} 小编觉得，责任链模式其实类似于我们生活中的“小环节串连起来变成大环节”，让我们在面对各种任务和问题时更加游刃有余和从容不迫。希望大家能够掌握这种使用广泛的设计模式，用好责任感和责任心，成为一个更好的人。","link":"/2019110162876/"},{"title":"关于提升nginx的性能","text":"提升nginx性能的技巧1. 调整worker_processes和worker_connections参数在nginx.conf中，worker_processes表示工作进程的数量，worker_connections表示每个进程能够同时处理的最大连接数。调整这两个参数可以提高nginx的性能。 例如，如果有8个CPU核心，可以将worker_processes设置为8，然后根据服务器的负载来调整worker_connections参数。 2. 启用缓存机制nginx可以通过缓存来减轻服务器的负载。在配置文件中启用缓存，可以大大提高nginx的性能。 例如，可以将缓存时间设置为1小时，可以减少对服务器的请求并提高响应速度。 3. 禁用不必要的模块nginx中有很多模块，可以根据需要启用或禁用不必要的模块，这可以提高nginx的性能。 例如，如果不需要gzip和SSL功能，可以禁用这两个模块。 4. 使用HTTP/2HTTP/2是新一代的HTTP协议，可以提高网站的性能。通过在nginx.conf中启用HTTP/2，可以大大提高nginx的性能。 5. 负载均衡nginx可以将请求分发到多个后端服务器，可以提高网站的可用性和性能。 例如，可以将请求分发到多台服务器，可以提高网站的处理能力并减少负载。 6. 压缩文件nginx可以在传输文件之前压缩文件，可以减少网络流量并提高响应速度。 例如，将文件压缩可以减少文件的大小，从而减少传输时间。 7. 优化配置文件nginx.conf是nginx的配置文件，可以通过优化配置文件来提高nginx的性能。 例如，可以使用include语句将配置文件分成多个文件，这样可以提高可读性并减少错误。 总结通过调整参数、启用缓存、禁用不必要的模块、使用HTTP/2、负载均衡、压缩文件和优化配置文件，可以大大提高nginx的性能。需要根据实际情况选择相应的优化技巧，以提高网站的可用性和性能。","link":"/2019062162876/"},{"title":"regex总结","text":"","link":"/2019091062876/"},{"title":"策略","text":"策略模式：简单而有效的解决方案策略模式是软件开发中最常用的模式之一，它可以帮助开发者分离算法，并使其可以在运行时互换。 Java开发者可以使用策略模式来轻松实现复杂的业务逻辑。例如，一个应用可以根据用户输入的金额来决定选择何种支付方式，这就可以用策略模式来实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//定义支付策略的抽象类public abstract class PaymentStrategy { public abstract void pay(int amount);}//实现支付策略的具体类public class CreditCardStrategy extends PaymentStrategy { public void pay(int amount) { System.out.println(&quot;使用信用卡支付&quot; + amount + &quot;元&quot;); }}public class CashStrategy extends PaymentStrategy { public void pay(int amount) { System.out.println(&quot;使用现金支付&quot; + amount + &quot;元&quot;); }}//定义一个类来控制这一过程public class PaymentContext { private PaymentStrategy paymentStrategy; public PaymentContext(PaymentStrategy paymentStrategy) { this.paymentStrategy = paymentStrategy; } public void pay(int amount) { paymentStrategy.pay(amount); }}//使用策略模式public class Main { public static void main(String[] args) { PaymentContext paymentContext = null; int amount = 1000; //选择使用信用卡支付 paymentContext = new PaymentContext(new CreditCardStrategy()); paymentContext.pay(amount); //选择使用现金支付 paymentContext = new PaymentContext(new CashStrategy()); paymentContext.pay(amount); }} 从上面的代码可以看出，策略模式是一种简单而有效的解决方案，它能够使代码变得容易维护，因为算法的变化不会影响到已有的代码。","link":"/2019121362876/"},{"title":"代理","text":"代理模式：当你无法自己处理事情时，找个代理众所周知，程序里面很多时候需要处理一些繁琐的事情，比如访问一个远程服务、打印一张大图等等，这些任务可能占用大量的内存和时间，导致程序出现卡顿甚至崩溃的情况。如果你是一个懒人，你会选择怎么做？ 没错，找个代理人！代理人可以替你完成这些事情，你只需要告诉他你的需求，让他去完成就好了。在程序里也是一样，我们可以使用代理模式来处理这些繁琐的事情。 代理模式是什么？代理模式是一种结构型设计模式，它允许我们为其他对象提供一个代理，以控制对这个对象的访问。代理对象通常充当客户端和目标对象之间的中介，它可以隐藏目标对象的复杂性并且可以在不改变目标对象的情况下，为客户端添加额外的功能。 代理模式怎么用？我们先来看一个例子：假设你需要访问一个远程服务获取一些数据，但是这个服务需要认证才能使用。你不想把认证信息暴露给客户端，也不想让客户端直接访问服务，怎么办？ 首先，我们定义一个接口Service，用来让代理和目标对象实现： 123public interface Service { void getData();} 然后，我们定义一个目标对象实现这个接口，用来访问远程服务： 12345678910111213public class RealService implements Service { private String authCode; public RealService(String authCode) { this.authCode = authCode; } @Override public void getData() { // 访问远程服务获取数据 System.out.println(&quot;获取数据&quot;); }} 接下来，我们定义一个代理类实现这个接口，并在构造函数中传入目标对象和认证信息。代理类的getData()方法里面先进行身份认证，然后再调用目标对象的getData()方法获取数据： 123456789101112131415161718public class ProxyService implements Service { private final Service realService; private final String authCode; public ProxyService(Service realService, String authCode) { this.realService = realService; this.authCode = authCode; } @Override public void getData() { // 进行身份认证 System.out.println(&quot;进行身份认证&quot;); // 调用目标对象的方法获取数据 realService.getData(); }} 最后，我们就可以在客户端中创建代理对象，而不是直接访问远程服务： 123456789public class Client { public static void main(String[] args) { // 创建代理对象 Service service = new ProxyService(new RealService(&quot;auth&quot;), &quot;auth&quot;); // 使用代理对象获取数据 service.getData(); }} 这样，我们就利用代理模式来实现了目标对象的访问控制，客户端无需知道目标对象的实现细节和认证信息，而且可以在代理对象中添加额外的功能，比如缓存数据、限流等。 总结代理模式是一种非常常用的设计模式，它能够让我们在不改变目标对象的情况下，对目标对象进行访问控制和功能扩展。在实际开发中，我们可以使用代理模式来优化程序的性能和安全性，减少系统的负担，提高用户体验，让程序变得更加健壮。","link":"/2019110762876/"},{"title":"docker概念","text":"","link":"/2022021162876/"},{"title":"docker使用","text":"","link":"/2022030162876/"},{"title":"docker架构","text":"","link":"/2022021462876/"},{"title":"docker的坑","text":"","link":"/2022032462876/"},{"title":"golang初识","text":"关于golang 2007年开发, 2009年开源, 2021年Go1稳定版 特点: 简 并行 迅速 用途: 游戏服务器 高性能分布式系统 运行: go run.hello.go 直接运行 go build hello.go 生成二进制文件, 然后 ./hello 运行文件 安装: 需要将c:\\go\\bin目录添加到path变量中 语言结构 包声明 第一行位置, package关键字 引入包 包声明之后, import关键字 函数 每个可执行程序必须包含main函数(没有init()函数情况下, 先执行main函数) 变量 语句&amp;表达式 注释 单行(推荐) /* 这里是多行注释 */ 基础语法 go标记 关键字 标识符 常量 字符串 符号 行分隔符 一行一个语句结束(推荐) 多行写在一行, 用”;”分隔(不推荐) 标识符 字母-数字-下划线 数字不开头 字符串连接 使用+ 关键字 25个关键字(java有50个) 36个预定义标识符 空格 变量的声明中必须使用空格, 比如: var photoNo int; 格式化字符串 使用fmt.Sprintf格式化, 并赋予新的值","link":"/2022012253225/"},{"title":"golang初识----数据类型, 变量","text":"数据类型 布尔型 数字类型 整型 uint8 uint16 uint32 uint64 int8 int16 int32 int64 浮点型 float32 float64 complex64: 32位实数和虚数 complex128: 64位实数和虚数 字符串类型 派生类型 指针类型Pointer 数组类型 结构化类型struct Channel类型 函数类型 切片类型 接口类型interface Map类型 其他 byte: 类似uint8 rune: 类似int32 uint: 32或64位 int: 与uint一样大小 uintptr: 无符号整型, 用于存放一个指针 变量 变量声明 声明(没初始化) var 变量名 类型 var 变量名1 类型, 变量名2 类型 默认为零值 数值类型为0 布尔类型为false 字符串为”” 其他类型为nil 根据值自动判定类型 := 多变量声明 类型相同, 非全局变量 var vname1, vname2, vname3 type vname1, vname2, vname3 = v1, v2, v3 全局变量 var( vname1 v_type1 vname2 v_type2 ) 常量 格式: const 变量名 类型(可省略) = 值 多个变量const(变量名1=值 变量名2=值 变量名3=值 ) iota的使用 可以被编译器修改的常量","link":"/2022020731734/"},{"title":"Golang vs Java","text":"Golang vs Java: 谁才是程序员的选择？现代编程领域中，压轴的两种语言无疑是 Go 和 Java。虽然两者都有着自己的优缺点，但在选择一种最合适的语言时，如何决定呢？本篇文章将对 Golang 和 Java 进行比较，旨在帮助程序员选择自己最喜欢的语言。 适用领域首先，我们来看一下两种语言适用的领域。 Golang 是 Google 开发的静态类型语言，受到了 C 和 Python 的启发。它适用于并发和分布式系统，因为它有着轻量级的线程（称为 goroutines）和基于 Channel 的通信机制。此外，Golang 的性能和封装特性也是其一大优势。 相对应的，Java 是一门广泛应用的语言，它是一门面向对象、跨平台的语言。Java 的优点是它拥有强大的库和生态系统，它的应用场景广泛且易于开发。 语法比较语法方面，两种语言都有各自的特点。 Golang 的语法非常简单明了，它没有类和继承的概念，但它有一个更加简单的 interface 概念。Golang 的结构也更加轻量级，这使得它在处理大量数据时比 Java 更快。 相反，Java 的语法相对复杂一些，但也更规范化。它的类和继承概念更加清晰，这对于大型项目十分重要。Java 的面向对象特性也使得它在一些特定领域的开发中更有优势。 性能对比性能一直是程序员关注的热点问题。 Golang 的并发执行和内存管理机制使其能够有效地处理大型程序。这也是为什么 Golang 被用于 Google 内部的大型项目，例如 Kubernetes 和 Docker 等项目。Golang 通过使并发执行变得容易来提高程序性能。 然而，Java 也有很好的优化性能选项。Java 的 JIT 编译器能够将代码动态解释并提高执行效率，结果是 Java 的应用程序不仅能够在桌面上执行，而且能够处理许多大型任务。 生态系统当然，技术生态系统也是程序员非常关心的问题。 Golang 的生态系统相对较新，但也发展得非常活跃。Golang 有许多优秀的库和框架，例如 Gin 和 Echo 等。它的社区也非常活跃，有越来越多的人使用 Golang 进行开发。 然而，Java 的生态系统更加成熟和庞大。Java 的生态系统种类繁多，包括几乎所有现代编程领域的库和框架。Java 的生态系统已经极具规模，许多企业级应用程序选择的就是 Java。 结论到底哪个更好，Golang 还是 Java？ 答案是取决于你的项目，应用程序以及经验。Java 是一门成熟、广泛使用的语言，但 Golang 则是一个更轻便、更快速的语言，适用于那些对并发和分布式系统的处理要求更高的开发人员。","link":"/2022062162876/"},{"title":"golang的使用","text":"Golang学习技巧 编写规范感觉这条总是出现在各类编程语言技巧文章里，但是 大部分 所有都非常实用啊！遵循规范+好的习惯，让代码可读性强、易于维护、扩展性好。以下是go中几个经典的规范： 符号命名 私有变量或函数：以小写字母开头，单词之间使用下划线 _ 连接 公有变量或函数：以大写字母开头，单词之间使用驼峰命名法 代码结构 将package和所在文件命名一致（名称要能体现功能） import时将标准库放在前面，第三方库放在后面 init()函数必要时可以使用 在编写代码时遵守命名规范、代码结构规范，可以提高可读性、可维护性、易扩展性。 Golang使用技巧指针、值传递go中可以传递指针，也可以传递值（int、string等）。如果是传递指针的话，被调用的函数可以在原变量上修改，否则不行。如： 123456789func main() { var num int = 0 fmt.Printf(&quot;%d&quot;, add_num(&amp;num))}func add_num(num *int) int { *num = 1 return *num} 这样在main函数中就会打印出1了。 defer关键字go中有一个非常优秀的关键字: defer。这个关键字可以“注册”一个函数，等当前函数执行完毕后再去执行。常常用于解决资源占用释放问题，比如是打开文件后后忘记关闭等问题，代码如下： 123456789func foo(filename string) error { f, err := os.Open(filename) if err != nil { return err } // 在函数执行完毕后关闭文件，无论函数结果如何都会执行 defer f.Close() // ... 此处省略其他逻辑处理 return nil} 并发处理go极其擅长并发处理，这是它设计之初就考虑到的。goroutine是go的轻量级线程，可以用来并发执行程序。示例代码如下： 12345678func main() { go do_job() // 新开一个线程执行函数，不阻塞主函数 // ... 此处省略其他逻辑处理}func do_job() { // ... 此处省略一些逻辑处理} 这样main函数会继续执行其他操作，而do_job则会在另一线程中并发执行。 反射反射是了解go程序的一种方法。它的作用是在运行时检查程序的结构、变量、接口等。以下是一个简单的反射示例： 12345func main() { var str string = &quot;hello&quot; var value reflect.Value = reflect.ValueOf(str) fmt.Printf(&quot;type: %v, kind:%v, value:%v&quot;, value.Type(), value.Kind(), value.Interface())} 在这个例子中，可以通过reflect.Value的函数获得变量的类型、种类、值（字符串类型的“hello”）等相关信息。","link":"/2022061062876/"},{"title":"golang避坑","text":"1. 不要使用多个初始化函数一些初学者会喜欢使用多个初始化函数，比如init1、init2等等，这是不好的写法。因为这些函数执行顺序并不是很明确，可能会导致依赖问题，因此推荐只使用一个init函数来进行初始化。 2. 不要忘记检查返回值使用golang必须要克服的一种毛病就是忘记检查返回值。这很危险，错误会悄悄地发生，并且不容易被发现。所以，对于所有的函数，都要检查其返回值，即使它只是一个简单的调用。 3. 不要使用未初始化的变量如果你尝试使用一个未初始化的变量，则会引发一些意想不到的问题。因此，要养成好习惯，一定要先初始化变量，然后再使用它们。 4. 不要在循环中使用defer如果你在循环中使用了defer，那么每次循环都会创建一个新的defer函数。这将会浪费大量内存，并可能导致你的程序异常崩溃。因此，在制定带defer函数的程序时，请确保其在循环之外。 5. 不要犯使用指针的错误这个问题可能在golang的初学者中非常普遍。请记住，如果您使用了指针，那么您应该始终检查它是否为nil。否则，您的代码可能会因为空指针而崩溃。所以，请务必学会在代码中正确地使用指针。","link":"/2022061562876/"},{"title":"Istio的实践","text":"Istio落地实践Istio是一个基于Service Mesh的开源项目，旨在通过解决微服务架构中的网络问题和安全问题，简化微服务的运维。本文将介绍如何在Java应用中使用Istio。 环境准备在开始之前，需要准备以下环境： Kubernetes集群 Istio安装包 Java应用 这里我们以minikube部署Kubernetes集群为例，使用以下命令安装Istio： 1istioctl manifest apply --set profile=demo 配置Istio注入要在Java应用中使用Istio，需要将Istio的Envoy Sidecar注入到应用容器中。可以通过以下命令对应用容器进行Istio注入： 1kubectl apply -f &lt;(istioctl kube-inject -f /path/to/deployment.yaml) 其中，deployment.yaml是Java应用的部署文件，通过kube-inject命令将会生成一个新的yaml文件，包含了注入Istio Sidecar的配置信息。 使用Istio实现服务发现和负载均衡在Istio中，可以通过配置VirtualService和DestinationRule实现服务发现和负载均衡。例如，以下是一个简单的VirtualService配置： 12345678910111213apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: my-appspec: hosts: - my-app http: - route: - destination: host: my-app port: number: 8080 该配置指定了一个名称为my-app的VirtualService，它将请求转发到名称为my-app的后端服务，端口号为8080。 同时，可以通过配置DestinationRule实现负载均衡。例如，以下是一个简单的DestinationRule配置： 123456789apiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata: name: my-appspec: host: my-app trafficPolicy: loadBalancer: simple: RANDOM 该配置指定了一个名称为my-app的DestinationRule，它使用随机负载均衡方式。 使用Istio实现流量管理在Istio中，可以通过配置VirtualService的route实现流量管理，例如可以将请求发送到特定的版本。 以下是一个简单的VirtualService配置，它将60%的请求发送到v1版本，40%的请求发送到v2版本： 12345678910111213141516171819202122232425262728293031323334353637apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: my-appspec: hosts: - my-app http: - route: - destination: host: my-app port: number: 8080 weight: 60 subset: v1 - destination: host: my-app port: number: 8080 weight: 40 subset: v2 ---apiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata: name: my-appspec: host: my-app subsets: - name: v1 labels: app: my-app version: v1 - name: v2 labels: app: my-app version: v2 使用Istio实现流量拦截和重试在Istio中，可以通过配置VirtualService的route实现流量拦截和重试。例如，以下是一个拦截请求的配置： 1234567891011121314151617181920212223apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: my-appspec: hosts: - my-app http: - match: - headers: x-myservice-requires-auth: exact: &quot;true&quot; fault: abort: status: 401 delay: percent: 50 fixedDelay: 5s route: - destination: host: my-app port: number: 8080 该配置指定了一个匹配规则，如果请求中的x-myservice-requires-auth头部是true，则拦截请求并返回401错误，同时在50%的请求上延迟5秒。 总结本文介绍了如何在Java应用中使用Istio实现服务发现、负载均衡、流量管理、流量拦截和重试等功能。通过Istio，可以有效地解决微服务架构中的网络问题和安全问题，简化微服务的运维工作。","link":"/2023011162876/"},{"title":"kubernetes的相关概念","text":"Kubernetes 相关概念Kubernetes 是一个开源的容器编排平台，用于自动化部署、扩展和管理容器化应用程序。在学习 Kubernetes 之前，我们需要先了解一下以下几个概念： 1. PodPod 是 Kubernetes 中最小的部署单元。通常情况下，一个 Pod 包含一个或多个容器，Pod 中所有容器都共享同一个网络命名空间、IP 地址和存储卷。Pod 提供了一种独立于主机的抽象，使得应用程序可以被部署在任意一个节点上。 以下是一个 Pod 的定义文件： 12345678910apiVersion: v1kind: Podmetadata: name: my-appspec: containers: - name: my-app-container image: my-app-image ports: - containerPort: 8080 2. ServiceService 是 Kubernetes 中用于暴露应用程序的一种机制。可以将多个 Pod 组织在一个 Service 中，Service 会负责将请求路由到这些 Pod 中任意一个。Service 可以通过 Cluster IP、NodePort、LoadBalancer 等模式进行访问。 以下是一个 Service 的定义文件： 123456789101112apiVersion: v1kind: Servicemetadata: name: my-app-servicespec: selector: app: my-app ports: - name: http port: 80 targetPort: 8080 type: NodePort 3. ReplicaSetReplicaSet 是 Kubernetes 中用于管理 Pod 副本数的一种机制。可以通过 ReplicaSet 来指定需要创建多少个 Pod 副本。如果有任何一个 Pod 发生故障，ReplicaSet 会自动启动一个新的 Pod 来替代它。 以下是一个 ReplicaSet 的定义文件： 12345678910111213141516171819apiVersion: apps/v1kind: ReplicaSetmetadata: name: my-app-replicasetspec: replicas: 3 selector: matchLabels: app: my-app template: metadata: labels: app: my-app spec: containers: - name: my-app-container image: my-app-image ports: - containerPort: 8080 4. DeploymentDeployment 是 Kubernetes 中用于管理应用程序部署的一种机制。可以通过 Deployment 来指定需要创建多少个 ReplicaSet，Deployment 会自动创建并管理这些 ReplicaSet。Deployment 还提供了回滚、滚动升级等功能。 以下是一个 Deployment 的定义文件： 1234567891011121314151617181920212223apiVersion: apps/v1kind: Deploymentmetadata: name: my-app-deploymentspec: replicas: 3 selector: matchLabels: app: my-app strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 template: metadata: labels: app: my-app spec: containers: - name: my-app-container image: my-app-image ports: - containerPort: 8080 5. NamespaceNamespace 是 Kubernetes 中用于对资源进行隔离和管理的一种机制。可以将不同的资源划分到不同的 Namespace 中，隔离它们的使用者和环境。可以通过 Namespace 来划分不同的环境（如开发、测试、生产）。 以下是一个 Namespace 的定义文件： 1234apiVersion: v1kind: Namespacemetadata: name: my-namespace 总结Kubernetes 中包含了多种概念和机制，本文介绍了其中的五个核心概念：Pod、Service、ReplicaSet、Deployment 和 Namespace。在实际使用 Kubernetes 进行应用程序部署和管理时，需要深入理解这些概念，才能发挥 Kubernetes 最大的价值。","link":"/2022100162876/"},{"title":"初识dubbo","text":"当服务越来越多, URL配置管理困难, F5硬件负载均衡器的单点压力也越来越大 进一步发展, 服务间依赖关系变得错综复杂, 甚至分不清那个应用在哪个应用之前启动 服务调用量也越来越大, 服务的容量问题就暴露出来, 这个服务需要多少台机器? 节点角色说明: Provider: 暴露服务的服务提供方 Consumer: 调用远程服务的服务消费方 Registry: 服务注册与发现的注册中心 Monitor: 统计服务的调用次调和调用时间的监控中心 Container: 服务运行容器 调用关系说明:0. 服务容器负责启动, 加载, 运行服务提供者 服务提供者在启动时, 向注册中心注册自己提供的服务 服务消费者在启动时, 向注册中心订阅自己所需的服务 注册中心返回服务提供者地址列表给消费者, 如果有变更, 注册中心将基于长连接推送变更数据给消费者 服务消费者, 从提供者地址列表中, 基于软负载均衡算法, 选一台提供者进行调用, 如果调用失败, 再选另一台调用 服务消费者和提供者, 在内存中累计调用次数和调用时间, 定时每分钟发送一次统计数据到监控中心 Dubbo框架设计一个划分10个层: 服务接口层(Service): 该层是与实际业务逻辑相关的, 根据服务提供方和服务消费方的业务设计对应的接口和实现 配置层(Config):对外配置接口, 以ServiceConfig和ReferenceConfig为中心, 可以直接new配置类, 也可用通过Spring解析配置生成配置类 服务代理层(Proxy): 服务接口透明代理,生成服务的客户端Stub和服务端Skeleton, 以ServiceProxy为中心, 扩展接口为ProxyFactory 服务注册层(Registry): 封装服务地址的注册与发现, 以服务URL为中心, 扩展接口为RegistryFactory, Registry和RegistryService. 可能没有服务注册中心, 此时服务提供方直接暴露服务 集群层(Cluster): 封装多个提供者的路及负载均衡, 并桥接注册中心, 以Invoker为中心, 扩展接口为Cluster, Directory, Router和LoadBalance. 将多个服务提供方组合为一个服务提供方, 实现对象服务消费方法来透明, 只需要与一个服务提供方进行交互. 监控层(Monitor): PRC调用次数和调用时间监控, 以Statistics为中心,扩展接口为MonitorFactory,Monitor和MonitorService. 远程调用层(Protocol): 封装RPC调用, 以Invocation和Result为中心, 扩展接口为Protocol, Invoker和Exporter. Protocol是服务域, 它是Invoker暴露和引用的主功能入口, 它负责Invoker的生命周期管理. Invoker是实体域, 它是Dubbo的核心模型, 其他模型都是向它靠拢, 或转换成它, 它代表一个可执行体, 可向它发起invoke调用, 它有可能是一个本地的实现, 也可能是一个远程的实现, 也可能一个集群实现. 信息交换层(Exchange): 封装请求响应模式, 同步转异步, 以Request和Response为中心, 扩展接口为Exchanger, ExchangeChannel, ExchangeClient和ExchangeServer. 网络传输层(Transport): 抽象mina和netty为统一的接口, 以Message为中心, 扩展接口为Channel, Transporter, Client, Server和Codec. 数据序列化层(Serialize): 可复用的一些工具, 扩展接口为Serialization, ObjectInput,ObjectOutput和ThreadPool. Dubbo对于服务提供方和服务消费方, 从框架的10层中分别提供了各自需要关心和扩展的接口, 构建整个服务生态(以服务提供方和服务消费方本身就是一个以服务为中心的)","link":"/2020040216e5a472/"},{"title":"Istioi相关概念","text":"Istio：一个现代化的服务网格平台 简介Istio是一个开源的服务网格平台，旨在解决现代云端软件应用程序的网络和安全问题。它为服务之间的通信提供了一种透明的方式，并提供了全面的流量管理、安全、性能和可观察性功能。 Istio是一个跨平台、可扩展、易于部署的服务网格，支持多种场景和部署模式。它可以与Kubernetes、Consul、Nomad等容器编排和服务发现工具无缝集成，支持多种语言和框架，如Java、Golang、Node.js和Spring Boot等。 核心概念Istio包括以下核心概念： 服务： 一个服务代表了一个应用程序或一组应用程序，它可以由多个实例组成，通常会被多个客户端调用。 代理： 一个代理是Istio控制平面中的一个组件，它负责拦截服务之间的请求和响应，以实现流量控制、安全和监控等功能。Istio支持两种代理：Envoy和Istiod。Envoy是一个高性能的C++代理，它可以直接部署在Kubernetes Pod中；Istiod是一个Go实现的Istio管控面的一部分。 控制平面： 控制平面负责Istio的规则和配置管理等工作，它包含了Istiod、Pilot、Citadel和Galley等组件。 数据平面： 数据平面负责处理Istio路由代理的流量和指令，它包含了Envoy和Istiod等代理。 核心功能Istio提供了以下核心功能： 流量控制Istio可以使用基于规则的方式控制服务之间的流量流向、路由和负载均衡等行为，从而实现A/B测试、蓝绿部署、金丝雀发布等现代化的部署模式。 安全Istio提供了一个安全的服务之间通信的解决方案，并支持细粒度的访问控制、服务认证和传输层安全等功能。这使得开发人员可以专注于业务逻辑而不必考虑安全性问题。 可观察性Istio提供了全面的监控、跟踪和日志记录功能，使得开发人员可以了解服务之间的交互、性能和问题。 服务治理Istio提供了服务注册、发现、负载均衡和故障恢复等服务治理功能，从而使得开发人员可以轻松管理分布式服务架构。 安装与部署Istio可以在多种部署环境中运行，例如Kubernetes、Nomad、Consul等。Istio提供了多种安装方式，例如Istio Operator、Helm Chart、istioctl等。安装Istio可以参考Istio官方文档。 总结服务网格是一种现代化的微服务架构，它可以解决多个服务之间的通信、安全和监控等问题。Istio是一个开源的服务网格平台，可以帮助开发人员和运维人员轻松构建和管理分布式系统。Istio提供了全面的流量管理、安全、性能和可观察性功能，可以在多种部署环境中运行，是一种非常实用的微服务架构。","link":"/2023010162876/"},{"title":"kubernetes的使用","text":"Kubernetes使用指南本文将介绍如何使用Kubernetes进行容器编排和管理，实现高效的应用部署和运行。 什么是KubernetesKubernetes是一个开源的容器编排和管理系统，用于自动化部署、扩展和管理容器化的应用程序。Kubernetes基于Docker等容器技术，提供了高可用、自我修复、负载均衡、服务发现等重要的功能，简化了应用程序的部署和管理。 Kubernetes基本概念在使用Kubernetes之前，需要了解一些基本概念。 Node：Node是Kubernetes集群中的一个工作节点，可以是物理机器或者虚拟机。 Pod：Pod是Kubernetes中最小的可部署单元，它可以包含一个或多个容器，共享相同的网络和存储资源。 ReplicaSet：ReplicaSet是一组Pod的副本集合，用于保证容器的高可用性。 Deployment：Deployment是一个ReplicaSet的管理器，用于控制Pod的创建、升级和回滚。 Service：Service是Kubernetes中抽象的逻辑概念，用于实现Pod之间的通信和负载均衡。 Namespace：Namespace是Kubernetes中用于隔离不同应用的虚拟集群，每个Namespace内部可以拥有自己的资源和对象。 Kubernetes环境准备在使用Kubernetes之前，需要准备一个Kubernetes集群，可以通过容器云服务、云原生平台等方式部署，也可以在自己的机器上使用Minikube进行本地测试。 使用Minikube部署Kubernetes集群Minikube是一个开源、跨平台的Kubernetes测试工具，可以在本地机器上快速部署一个单节点的Kubernetes集群，用于开发和测试应用程序。 安装Minikube和kubectl命令行工具 下载安装Minikube和kubectl命令行工具： 123456curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ &amp;&amp; sudo install minikube-linux-amd64 /usr/local/bin/minikubecurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl \\ &amp;&amp; chmod +x ./kubectl \\ &amp;&amp; sudo mv ./kubectl /usr/local/bin/kubectl 启动Minikube集群 启动一个Minikube集群，并设置容器的运行环境为Docker： 1minikube start --vm-driver=docker 在启动过程中，Minikube会下载Docker镜像和Kubernetes组件，并创建一个单节点的Kubernetes集群。 部署应用程序 在Minikube集群中部署应用程序，可以通过以下步骤进行： 创建Deployment 创建一个Deployment，并指定部署的镜像和副本数： 1kubectl create deployment myapp --image=nginx --replicas=3 该命令会创建一个名为“myapp”的Deployment，使用Nginx镜像进行部署，并创建3个Pod。 创建Service 创建一个Service，并将其暴露到集群内部： 1kubectl expose deployment myapp --type=NodePort --port=80 该命令会创建一个NodePort类型的Service，将Deployment中的Pod映射到Node的随机端口，并将端口80暴露给集群内部的其他应用程序。 访问应用程序 使用Minikube提供的命令行工具可以快速打开应用程序的web界面： 1minikube service myapp 该命令会打开默认浏览器，并将应用程序的web界面显示出来。 使用Kubernetes进行应用部署使用Kubernetes进行应用部署的基本流程包括以下几个步骤： 编写Dockerfile Dockerfile是一个包含构建Docker镜像的指令的文本文件，其中包含了指定的操作系统、应用程序、库等内容。可以使用Java语言编写应用程序，然后将其打包成JAR文件，并使用Dockerfile构建Docker镜像。 构建Docker镜像 使用Dockerfile构建Docker镜像，可以使用以下命令： 1docker build -t myapp . 该命令会将当前目录下的Dockerfile文件和依赖文件打包成一个Docker镜像。 上传Docker镜像 将构建好的Docker镜像上传到Docker仓库，以便在Kubernetes中使用。 1docker push myrepo/myapp 假设自己有一个名为“myrepo”的Docker仓库，并希望将镜像上传到该仓库。需要先登录到该仓库： 1docker login myrepo 创建Deployment 在Kubernetes中创建Deployment，可以使用以下命令： 1kubectl create deployment myapp --image=myrepo/myapp --replicas=3 该命令会创建一个名为“myapp”的Deployment，并指定使用自己上传到Docker仓库中的镜像，创建3个Pod。 创建Service 为了让其他应用程序可以访问部署的应用程序，需要创建一个Service。可以使用以下命令： 1kubectl expose deployment myapp --type=LoadBalancer --port=80 该命令会创建一个LoadBalancer类型的Service，并将Deployment的Pod映射到外部IP地址和端口80。 访问应用程序 可以使用Service的外部IP地址和端口访问部署的应用程序，也可以使用Kubernetes提供的Ingress Gateway进行管理和访问控制。 总结本文介绍了Kubernetes的基本概念和使用方法，以及如何使用Minikube进行本地测试和应用部署。Kubernetes具有强大的容器编排和管理能力，可以简化应用程序的部署和管理，提高生产效率和安全性。希望本文对读者有所帮助，欢迎大家探索更多Kubernetes的应用场景和功能。","link":"/2012101062876/"},{"title":"kubernetes的实践","text":"Kubernetes落地实践简介Kubernetes 是一款开源的容器编排和管理工具，可以帮助我们更高效地管理云原生环境中的容器应用。在本文中，我们将介绍如何将 Kubernetes 应用于真实的生产环境中，并展示具体的实践经验。 准备工作在开始使用 Kubernetes 之前，需要先完成以下准备工作： 部署 Kubernetes 集群：可以使用 Kubespray、Kops、Minikube 等工具来快速部署 Kubernetes 集群； 部署容器镜像仓库：可以使用 Docker Registry 或者 Harbor 等容器镜像仓库来存储和管理镜像； 部署监控和日志工具：可以使用 Prometheus、Grafana、ELK 等工具来监控容器的状态和收集日志。 实践案例部署 Spring Boot 应用假设我们已经有一个简单的 Spring Boot 应用，需要将它部署到 Kubernetes 集群中。以下是具体的步骤： 将应用打包成容器镜像，并上传到镜像仓库中： 12345678# 编写DockerfileFROM openjdk:8-jdk-alpineCOPY target/demo-0.0.1-SNAPSHOT.jar /app.jarENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/app.jar&quot;]# 打包镜像docker build -t &lt;image_name&gt;:&lt;tag&gt; .# 上传镜像docker push &lt;image_name&gt;:&lt;tag&gt; 编写 Kubernetes 配置文件（deployment.yml）： 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: demospec: replicas: 3 selector: matchLabels: app: demo template: metadata: labels: app: demo spec: containers: - name: demo image: &lt;image_name&gt;:&lt;tag&gt; ports: - containerPort: 8080 应用 Kubernetes 配置文件： 1kubectl apply -f deployment.yml 部署分布式应用假设我们需要部署一个分布式应用，包含多个微服务，这些微服务需要相互调用。以下是具体的步骤： 使用 Kubernetes 部署 Redis，用于服务之间的数据共享： 12345678910111213141516171819202122232425262728293031apiVersion: apps/v1kind: StatefulSetmetadata: name: redisspec: serviceName: redis replicas: 3 selector: matchLabels: app: redis template: metadata: labels: app: redis spec: containers: - name: redis image: redis:alpine ports: - containerPort: 6379 volumeMounts: - name: data mountPath: /data volumeClaimTemplates: - metadata: name: data spec: accessModes: [ &quot;ReadWriteOnce&quot; ] resources: requests: storage: 1Gi 部署服务网关（使用 Istio）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344apiVersion: networking.istio.io/v1beta1kind: Gatewaymetadata: name: gatewayspec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - &quot;*&quot;---apiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata: name: demospec: hosts: - &quot;*&quot; gateways: - gateway http: - route: - destination: host: api-service port: number: 8080 weight: 100---apiVersion: networking.istio.io/v1beta1kind: DestinationRulemetadata: name: api-servicespec: host: api-service trafficPolicy: loadBalancer: consistentHash: httpHeaderName: &quot;x-correlation-id&quot; httpCookie: name: &quot;X-Correlation-ID&quot; 部署微服务之间的通信： 1234567891011121314151617181920212223242526272829303132333435363738394041424344apiVersion: apps/v1kind: Deploymentmetadata: name: apispec: replicas: 3 selector: matchLabels: app: api template: metadata: labels: app: api spec: containers: - name: api image: &lt;image_name&gt;:&lt;tag&gt; ports: - containerPort: 8080 env: - name: REDIS_HOST value: redis.default.svc.cluster.local - name: REDIS_PORT value: &quot;6379&quot; - name: REDIS_PASSWORD valueFrom: secretKeyRef: name: redis-secret key: password---apiVersion: v1kind: Servicemetadata: name: api-service labels: app: apispec: selector: app: api type: ClusterIP ports: - name: http port: 8080 targetPort: 8080 在上述配置中，我们使用了 Istio 进行服务网关和流量控制，并使用 Redis 存储微服务之间的数据。 总结在实际的生产环境中，Kubernetes 可以帮助我们更高效地管理容器应用，并提供了丰富的功能和插件，例如服务发现、负载均衡、故障恢复、流量控制等。在使用 Kubernetes 之前，需要做好充分的准备工作，并根据实际的情况进行设计和优化。","link":"/2022112162876/"},{"title":"kubernetes的架构特点","text":"Kubernetes架构特点Kubernetes是一个开源的容器编排和管理平台。它的架构设计灵活，可扩展性强，是现代云原生环境下非常受欢迎的技术。 架构概述Kubernetes的架构包含以下几个核心组件： API Server etcd kubelet kube-proxy 控制器管理器 调度器 其中，API Server是整个Kubernetes系统的核心，用于对外提供REST API服务，所有其他组件都通过访问API Server来对集群资源进行管理。 etcd是Kubernetes的数据存储（datastore）组件，用于存储集群的配置信息和状态信息。Kubernetes的API对象都存储在etcd中。 kubelet是每个节点上运行的代理程序，用于管理节点上的容器和镜像。它通过和API Server交互，获取需要在本节点上运行的Pod和容器信息，并通过CRI（Container Runtime Interface）与容器运行时（如Docker）进行交互。 kube-proxy是Kubernetes集群中的网络代理组件，它负责实现集群内Service和Pod的网络通信。 控制器管理器是Kubernetes集群中的核心组件之一，它包含了多个控制器，如Replication Controller、Deployment Controller等，用于确保集群中的Pod数量和状态达到期望值。 在Kubernetes中，Pod是最小的部署单位，它包含了一个或多个容器，并共享同一组网络和存储资源。通过调度器将Pod绑定到节点上，从而实现Pod的部署和管理。 架构特点Kubernetes的架构设计具有以下几个特点： 分布式架构：Kubernetes的组件可分布在多个节点上，通过etcd进行信息交互和状态同步。这种设计使得Kubernetes具有良好的可扩展性和高可用性。 服务抽象层：Kubernetes通过Service抽象层对底层网络进行了封装，使得集群内的应用可以彼此访问，而无需考虑底层网络拓扑和IP地址变化等问题。 软件定义：Kubernetes通过API对象的方式来描述集群资源和状态，提供了灵活的编程接口和丰富的扩展机制，使得开发者可以方便地管理集群中的应用。 弹性伸缩：Kubernetes支持水平扩展和收缩应用，通过控制器和调度器确保集群状态和需求的一致性。这种机制可以提供高效的资源利用和快速的应用弹性伸缩。 开放性和生态：Kubernetes是一个开源的项目，具有活跃的社区和庞大的生态系统，可以和各种云计算和容器技术集成，从而满足不同场景下的需求。 结语Kubernetes的架构设计使得它能够轻松地管理云原生应用，并具有高可用性、弹性伸缩、软件定义等特点。随着云原生应用的快速发展，Kubernetes已成为不可或缺的技术之一，它将引领应用容器的未来发展。","link":"/2022111362876/"},{"title":"java管用法","text":"","link":"/2020042162876/"},{"title":"java.util.ArrayList","text":"","link":"/2018051835c77a54/"},{"title":"java.util.Arrays","text":"","link":"/201805175a746145/"},{"title":"java.util.HashSet","text":"","link":"/20180602e2b6b443/"},{"title":"java.util.LinkedHashMap","text":"","link":"/20180608f72406f4/"},{"title":"java.util.HashMap","text":"","link":"/201805205326a00f/"},{"title":"java.util.LinkedHashSet","text":"","link":"/201806054accc084/"},{"title":"java.util.LinkedList","text":"","link":"/20180519ba93fcdb/"},{"title":"其他容器类","text":"","link":"/20180618f0ee3604/"},{"title":"容器类的使用相关","text":"","link":"/20180619fa835a24/"},{"title":"juc源码","text":"","link":"/2018010162876/"},{"title":"juc总结","text":"","link":"/2018010162876/"},{"title":"juc-1","text":"多线程-入门知识线程概念线程：我们追踪程序运行的流程，其实就是在追踪线程的流程。 单线程: “在某一时间点执行的处理只有一个”。（在研究单线程的时，我们忽略Java的后台线程，如：GC等） 多线程：常见的多线程常见有以下几个。 耗时的IO处理： 多个客户端：如果让服务端针对不同的客户端执行处理，程序是很复杂的。 客户端连接到服务器时，为客户端准备一个线程，这样看来服务器程序好像只处理一个客户端。 ps：nio即便不使用多线程，也可用执行兼具性能和可扩展性的IO处理。 例子HelloThread.java “本线程” &amp; “当前线程” 本线程: 表示this(以及this对应的线程)的意思 当前线程: 表示调用对象方法的线程 顺序 并行 并发 顺序:依次处理 并行:同时处理 并发: 将一个操作分隔成多个部分并且允许无序处理 启动两种方式 Thread类: 继承Thread类的例子 Runnable接口:实现Runnable接口的例子 其他方式 - java.util.concurrent.ThreadFactory利用ThreadFactory启动线程 无论那种方式,启动新线程的方法最终都是Thread类的start方法。 ps：Thread类本身还实现Runnable接口，并持有run方法，但run()主体是空的。仍需要子类重写。 线程类的实例 &amp; 线程需要注意的是线程类的实例并不等于线程。线程就算停止，线程类的实例并不会消失。 暂停（休眠）在实际程序中，使用sleep的频率并不高。Sleep的例子 interrupt方法：用于中途唤醒被Thread.sleep休眠的线程 互斥线程A和线程B相互竞争引起与预期相反的情况称为竞态条件(race condition)或数据竞争(data race)。 处理上述的竞态的操作称为互斥。 synchronized方法（同步方法）synchronized例子 synchronized代码块synchronized代码块用于精准控制互斥处理的执行范围。 synchronized实例方法和synchronized代码块（this加锁）以下两种写法是等效的。也就是说synchronizedui实例方法是使用this的锁来执行线程的互斥处理的。 123synchronized void method(){ ...} 123456void method(){ synchronized(this){ .... }} synchronized静态方法和synchronized代码块（类对象加锁）synchronized静态方法每次只能由一个线程运行,这一点和synchronized实例方法相同。但是，synchronized静态方法使用的锁和synchronized实例方法使用的锁是不一样的。 12345class Something{ static synchronized void method(){ ... }} 123456789class Something{ static void method(){ synchronized(Something.class){ ... } }}也就是说，synchronized静态方法是使用该类的类对象的锁来执行线程的互斥处理的。Something.class是Something类对应的java.lang.class类的实例。 协作wait方法，notify方法，notifyAll方法(都是java.lang.Object类的方法,所以既不是Thread类中的方法，但又是) 注意:它们只能由持有要调用的实例的锁的线程调用。如果未持有锁的线程调用上面方法，异常java.lang.IllegalMonitorStateException会抛出。 为什么放在java.lang.Object包? 这三个方法与其说是针对线程的操作,不如说是针对实例的等待队列的操作。由于所有的实例都有等待队列。它们确实不是Thread包的方法，但Object是所有类的父类，所以也可用说它们是Thread类的方法。 等待队列（线程的休息室）所有实例都拥有一个等待队列，它是在实例的wait方法执行后停止操作的线程的队列。 线程退出等待队列等待队列是一个虚拟的概念, 既不是实例中的字段,也不是用于获取正在实例上等待的线程的列表的方法。 其他线程的notify或notifyAll方法来唤醒线程 其他线程的interrupt方法流唤醒线程 wait方法超时 wait方法：线程放入等待队列要执行wait方法，线程必须持有锁（这是规则）。如果线程进入等待队列之后，便会释放其实例的锁。 12wait();this.wait(); //等同于上面, 这里可以说线程正在this上wait notify方法要执行notify方法，线程也必须持有调用的实例的锁。 12obj.notify();那么obj的等待队列中的线程便会被选中和唤醒,然后就会退出等待队列。 notify唤醒的线程并不会在执行notify的一瞬间重新运行。因为在执行notify的那一瞬间，执行notify的线程还持有着锁，所以其他线程还无法获取这个实例的锁。 执行notify后如何选择线程：假如在执行notify方法之后，正在等待队列中等待的线程不止一个，对于“这时该如何来选择线程”这个问题规范中并没有做出规定。究竟是选择最先wait的线程，还是随机选择，或采取其他方法取决于Java平台运行环境。因此编写程序时需要注意，最好不要编写依赖于所选线程的程序。 notifyAll方法notifyAll方法会将等待队列中所有的线程都取出来。 123notifyAll();this.notifyAll(); 锁在谁的手里? 被唤醒的线程会去获取其他线程在进入wait状态时释放的锁。其实是执行notifyAll的线程正持有着锁。因此，唤醒的线程虽然都推出了等待队列，但都在等待获取锁，处于阻塞状态。只有在执行notifyAll的线程释放锁以后，其中的一个幸运儿才能够实际运行。 - 使用notify方法还是notifyAll方法？由于notify唤醒的线程较少，所以处理速度要比使用notifyAll快。但使用notify时，如果处理不好，程序便可能会停止。一般来说，使用notifyAll时的代码会比notify时更为健壮。 线程的状态转移参考下图的线程状态转移：","link":"/2020011840750/"},{"title":"juc-02-评价标准","text":"多线程-评价标准安全性(必备条件):不损坏对象对象损坏是一种比喻，实际上，对象是内存上的一种虚拟事物，并不会实际损坏。对象损坏是指对象的状态和设计者的意愿不一致， 通常是指对象的字段的值并非预期值。 如果一个类即使被多个线程同时使用，也可确保安全性，那么这个类就称为线程安全（thread-safe）类。由于类库中还存在非线程安全的类，所有在多线程的程序中需要特别注意。比如：java.util.Vector类是线程安全的类,而java.util.ArrayList则是非线程安全的类。 线程安全和线程兼容：虽然ArrayList是非线程安全的，当通过执行适当的互斥处理，也可用安全使用。 synchronized和线程安全：某个线程是线程安全的还是非线程安全的，与这个类的方法是否synchronized方法无关。 生存性(必备条件):必要的处理能够被执行生存性（liveness）是无论是什么时候，必要的处理都一定能够被执行。 即使对象没有损坏，也不代表程序就一定好。极端一点说，假如程序在运行过程中突然停止了，这时，由于处理已经停止，对象的状态就不会发生变化了，所以对象状态也就不会异常。这虽然符合前面将的“安全性”条件，当无法运行的程序根本没有任何意义。无论是什么时候，必要处理都一定能够被执行。 有时候安全性和生存性是相互制约的。例如，有时只重视安全性，生存性就会下降。最典型的是死锁（deadlock），即多个线程相互等待对方释放锁的情形。 可复用性（提升质量）: 类可重复利用类如果能够作为组件从正常运行的软件中分割出来，就说明这个类有很高定复用性。 编写多线程的时候如果能够巧妙地将线程的互斥机制和方针隐藏到类中，那这就是一个可复用性高的程序。 性能（提升质量）: 快速,大批量地执行处理 吞吐量：单位时间内完成的处理数量。能完成的处理越多，则吞吐量越大。 响应性（等待时间）：从发出请求到收到响应的时间。 容量：可同时进行的处理数量 其他 效率： 可伸缩性： 降级：","link":"/2020011925417/"},{"title":"juc-03","text":"关于synchronizedsynchronized语法&amp;Before/After模式123synchronized void method(){}synchronized (obj){} 其实可以看做是“{”处获得锁，“}”处释放锁。 假设，存在一个获得锁的lock方法，或释放锁的unlock方法。 123456789101112131415161718192021显示处理锁的方法：void method(){ lock(); ... unlock();}如果在lock方法和unlock方法之间存在return，那么锁将无法被释放。void method(){ lock(); if(条件表达式){ return; //这里执行了return，unlock()就不会被调用。 } unlock();}void method(){ lock(); doMethod(); //如果该方法抛出异常，unlock()就不会被调用 unlock();} 上述问题并不仅仅在于return语句，异常处理也存在这样的问题，调用的方法（或该方法调用的方法） 抛出异常时候，锁也就无法被释放。 避免异常导致的问题，必须使用finally语句 12345678void method(){ lock(); try{ ... }finally{ unlock(); }} synchronized在保护什么synchronized就像门上的锁。当你看到门上的锁时，我们还应该确认其他的门和窗户是不是都锁好了。只要是访问多个线程共享的字段的方法，就需要使用synchronized进行保护。 该以什么单位来保护呢？12345678910111213141516171819202122232425public class Gate { //已经通过的人数 private int counter = 0; //最后一个通行者的“姓名” private String name = &quot;Nodody&quot;; //最后一个通行者的出生地 private String address = &quot;Nowhere&quot;; /** * 添加：synchronized * 表示通过门 * @param myname * @param myaddress */ public synchronized void pass(String myname, String myaddress) { this.counter++; this.name = name; try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } this.address = address; }} 比如上面的代码，已经在pass方法上加了synchronized方法。 如果set和get方法都同时加上synchronized并不能保证安全 原子操作synchronized方法只允许一个线程同时执行。如果某个线程正在执行synchronized方法，其他线程就无法进入该方法。也就是说，从多线程的角度来看，这个synchronized方法执行的操作是“不可分割的操作”。这种不可分割的操作通常称为“原子atomic”操作。 atom是物理学中的“原子”，本意为不可分割的物体。 long与double的操作不是原子的Java中定义了一些原子的操作。 例如char，int等基本类型的赋值和引用都是原子的；引用类型的赋值和引用操作也是原子的。因此，就算不使用synchronized也不会被分割。 例外：long和double的赋值和引用操作并不是原子的。 最简单的方法就是在synchronized方法中执行；或字段上加上volatile关键字。 总结： 基本类型，引用类型的赋值和引用是原子操作 long和double的赋值和引用都是非原子操作 long或double在线程间共享时，需要将其放入synchronized中操作，或声明为volatile。","link":"/2020012039262/"},{"title":"juc-04","text":"java.util.concurrent包和计数信号量计数信号量和Semaphore类Single Threaded Execution模式用于确保某个区域“只能有一个线程”执行。下面我们将这种模式扩展。确保某个区域“最多只能由N个线程”执行。这时就要用计数信号量来控制线程数量。 假设能够使用的资源个数为N个，而需要这些资源的线程个数又多于N个。此时就会导致竞态。 java.util.concurrent包中提供了表示信号量的Semaphore类。 资源的许可个数（permits）将通过Semaphore的构造函数来指定。 Semaphore的acquire方法用于确保存在可用资源。当存在可用资源的时候，线程会立即从acquire方法返回，同时信号量内部的资源个数会减1。如果没有可用资源，线程则阻塞在acquire方法内，知道出现可用资源。 Semaphore的release方法用于释放资源。释放资源后，信号量内部的资源个数会增加1。另外，如果acquire中存在等待的线程，那么其中一个线程会被唤醒，并从acquire方法返回。 使用Semaphore类的示例程序使用例子","link":"/2020012123327/"},{"title":"juc-05","text":"finalfinal类表示该类无法扩展。也就是说，无法创建final类的子类。 由于无法创建final类的子类，所以final类中声明的方法也不会被重写。 final方法表示该方法不会被子类的方法重写。 如果在静态方法的声明上加上final，则表示该方法不会被子类的方法隐藏（hide）。如果试图重写或隐藏final方法，编译时会提示错误。 在设计模式的Template Method中，有时候模板方法会声明为final方法。 final字段表示该字段只能赋值一次。 12345678910111213141516171819202122232425final字段赋值有两种方式： 1.字段声明的时候赋值 class Something{ final int value = 123; } 2.字段在构造方法中赋值 class Something{ final int value; Something{ this.value = 123; } } final静态字段赋值两种方法： 1.字段声明时赋值 class Something{ static final int value = 123; } 2.静态代码块中赋值 class Something{ static final int value; static { value = 123; } 注意: final字段不可用setValue这样的setter方法再次赋值. final与创建线程安全的实例从创建线程安全的角度来说,将字段声明为final是非常重要的。 final变量和final参数局部变量和方法的参数也可用声明为final。final变量只可以赋值一次。 而final参数不可以赋值，因为在调用方法时，已经对其赋值了。","link":"/2020012239902/"},{"title":"juc-06","text":"集合类与多线程管理多个实例的接口或类统称为集合（collection）。 Java中的大部分集合都是非线程安全的。因此，在多线程操作集合的时候，需要去查看API文档， 确认要用的类或接口是否线程安全的。 例子1：非线程安全的java.util.ArrayList类该例子中ArrayList(及迭代器)在被多个线程同时读写而失去安全性时,便会抛出ConcurrentModificationException异常。该运行时（runtime）的异常用于表示“执行并发修改了”。 异常不过是调查Bug根本原因的提示而已，所以编写编程不能依赖于抛出的异常。 例子 例子2: 利用Collections.synchronized方法所进行的同步对例子1的改造，使得其具有安全性。 例子2 通过Collections.synchronizedList方法同步ArrayList实例 通过使用list同步后的读线程 “写”线程是显示调用add方法和remove方法,故可以不做调整。 12345synchronized(list){ for(int n : list){ System.out.println(n); }} 例子3: 使用写时复制(copy-on-write)的java.util.concurrent.CopyOnWriteArrayList类例子2使用Collections.synchronized进行同步。这里使用CopyOnWriteArrayList类通过copy-on-write避免读写冲突。 12345678public class Main { public static void main(String[] args) { //这里使用Copy-on-write final List&lt;Integer&gt; list = new CopyOnWriteArrayList&lt;Integer&gt;(); new WriterThread(list).start(); new ReaderThread(list).start(); }} 程序如果频繁“写”操作，使用copy-on-write会比较耗时，如果写操作比较少，读操作比较多，是比较适合使用的。","link":"/2020012339582/"},{"title":"juc-08","text":"中断状态与InterruptedException异常的相互转换中断状态-&gt;InterruptedException异常的转换InterruptedException异常-&gt;中断状态的转换InterruptedException异常-&gt;InterruptedException异常的转换","link":"/2020012524095/"},{"title":"juc-07","text":"理解InterruptedException异常可能会花费时间,但可以取消当习惯Java多线程设计之后,我们会留意方法后面是否加了throws InterruptedException. 如果方法加了,则表明该方法(或该方法进一步调用的方法中)可能会抛出InterruptedException异常. 这里包含两层意思: “花费时间”的方法 “可以取消”的方法 换言之,加了throws InterruptedException的方法可能会花费时间,当可以取消. 加了throws InterruptedException的方法 java.lang.Object类的wait方法 java.lang.Thread类的sleep方法 java.lang.Thread类的join方法 花费时间的方法可以取消的方法sleep方法和interrupt方法wait方法和interrupt方法join方法和interrupt方法interrupt方法只是改变中断状态isInterrupted方法: 检查中断状态Thread.interrupted方法: 检查并清除中断状态不可用使用Thread类的stop方法","link":"/2020012423135/"},{"title":"juc-09","text":"java.util.concurrent包与线程同步java.util.concurrent.CountDownLatch类java.util.concurrent.CyclicBarrier类","link":"/2020012640670/"},{"title":"juc-12","text":"需要解决的问题实例不一致 资源问题 提升性能部分：Immutable 整体：Read-Write Lock模式 提高响应性尽可能缩小临界区的范围，降低线程冲突的概率，这样就可以抑制性能的下降。 Thread-Per-Message 多线程的评价标准：四个指标 安全性 生存性 可复用性 性能 死锁","link":"/2020012951614/"},{"title":"juc-10","text":"关于java.lang.ThreadLocal类java.lang.ThreadLocal就是储物间java.lang.ThreadLocal与泛型","link":"/202001272079/"},{"title":"kafka入门","text":"Kafka 相关概念Kafka 是一款高吞吐量、分布式、可持久化的消息系统，具有以下特点： 高吞吐量：Kafka 可以处理大量的消息流，每秒能够处理上百万条消息。 分布式系统：Kafka 可以在多台服务器上运行，实现消息的分布式处理和存储。 可持久化的消息存储：Kafka 通过消息存储机制，保证消息的可靠传递和持久化存储。 本文将介绍 Kafka 的相关概念。 TopicTopic 是 Kafka 中消息发送和接收的单位，每个 Topic 包含多个消息，每个消息由一个 Key 和一个 Value 组成，通常 Key 用于分割消息流，Value 用于存储具体的消息内容。 创建 Topic：可以通过 Kafka 的命令行工具或者 API 来创建 Topic。 分区：每个 Topic 可以分为多个分区，每个分区可以在不同节点上存储和处理，实现消息的并行处理。 副本：为了保证消息的可靠传递，每个分区可以有多个副本，分布在不同的节点上，当主副本故障时，备用副本可以接替主副本的功能。 ProducerProducer 是生产者，负责向 Kafka 发送消息并将消息写入 Topic 的分区中。 发送消息：Producer 可以通过 Kafka 的 API 来发送消息，向指定 Topic 发送消息。 确认机制：Producer 发送消息后，可以通过确认机制获得发送消息的状态。 ConsumerConsumer 是消费者，负责从 Kafka 中读取消息并处理消息。 订阅消息：Consumer 可以通过 Kafka 的 API 来订阅 Topic 上的消息。 分配分区：当 Consumer 订阅某个 Topic 后，需要为其分配分区，以实现消息的并行消费。 确认机制：消费者也可以通过确认机制来确认收到的消息，从而保证消息的可靠接收和处理。 BrokerBroker 是 Kafka 的消息中间件，负责接收和处理 Producer 发送的消息、为 Consumer 提供消息服务。 存储和处理：Broker 负责存储和处理 Kafka 中的消息，实现消息的持久化存储和并行处理。 管理 Topic、Partition 和 Replica：Broker 具有管理 Topic、Partition 和 Replica 的功能，可以实现动态扩展和缩小 Kafka 集群的节点数量，以适应不同的业务需求。 队列存储：Broker 使用队列存储的方式，实现高性能的消息处理和传递。 ZooKeeperZooKeeper 是分布式系统协同服务，Kafka 集群中需要使用 ZooKeeper 来进行分布式协调和管理。 为 Kafka 派发 Broker ID：ZooKeeper 可以为 Kafka Server 派发全局唯一的 Broker ID，以实现集群内部的节点通信。 管理元数据：ZooKeeper 管理了 Kafka 集群中的元数据，包括 Topic、Partition、Broker 等信息。 监控：ZooKeeper 可以对 Kafka 集群的状态进行监控和统计，发现和解决问题。 ConclusionKafka 是一款高性能、分布式的消息中间件，支持可靠，高容错性的消息处理，并可轻松与各种数据系统集成。通过学习 Kafka 的相关概念，可以更好地了解和掌握 Kafka 的使用和实践。","link":"/2020101862876/"},{"title":"juc-11","text":"线程的优先级Java的优先级只在特定的Java平台运行环境起作用Java的优先级只在特定的运行环境(JVM的实现和版本,以及操作系统)有效,Java规范中提到”优先级高的线程先执行”, 并没有写”优先”的具体体系,因此没有太多的意义. 便是优先级的静态字段Java线程的优先级是整数值(int) Thread.MIN_PRIORITY: 最低 Thread.NORM_PRIORITY:默认 Thread.MAX_PRIORITY:最高 设置优先级的方法setPriority方法用于设置优先级,是Thread类的实例方法. 获取优先级的方法getPriority方法用于获取优先级,是Thread类的实例方法.","link":"/2020012851422/"},{"title":"kafka架构","text":"Kafka 架构Kafka 架构Kafka 架构主要分为以下几个部分： Topic：消息的录入点，每个 Topic 可以被分成多个 Partition，每个 Partition 可以存储多个消息。 Producer：消息的生产者，负责往 Kafka 集群中的 Topic 发送消息，将消息放到指定的 Partition 中。 Broker：消息经过 Producer 生产后，会发送到多个 Broker 上，Broker 维护了消息的持久化存储和 Snapshot 文件，使得 Kafka 集群可以在 Broker 崩溃或网络故障的情况下依然可以保证消息的持久性。 Consumer：消息的消费者，从指定的 Topic 的 Partition 中消费消息，消费后的消息将不能被再次消费，一旦消息被消费，该消费者就读取该消息的 Offset 位置，以便下一次从该位置开始消费。 ZooKeeper：用于管理 Broker 集群，负责维护集群中每个 Broker 的元数据，并且在 Broker 发生变化时通知 Consumer。 Kafka 的工作流程 Producer 将消息发送到 Broker。 Broker 将消息持久化到磁盘，并将消息存储到对应的 Partition 中。 Consumer 从指定的 Partition 中消费消息，并将 Offset 位置保存到 ZooKeeper 中。 当有新消息到达时，Consumer 将自动从上一次消费的 Offset 位置继续消费。 Java 代码示例以下是一个简单的 Java 代码示例，展示了如何使用 Kafka 的 Producer 模块发送消息到指定的 Topic 中： 12345678910111213141516// 配置 Kafka 生产者Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);// 创建 Kafka 生产者Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);// 生产并发送消息for (int i = 0; i &lt; 100; i++) { producer.send(new ProducerRecord&lt;&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i)));} // 关闭 Kafka 生产者producer.close(); 结语Kafka 是一个强大的消息引擎，它可以使得大规模数据处理变得更加高效、灵活，适合于各种大数据处理场景。希望本文能为大家对 Kafka 的理解和应用提供帮助。","link":"/2020091062876/"},{"title":"rocketmq概念","text":"RocketMQ消息中间件概念你有没有想过，如果我们需要向成千上万的用户发送消息，该怎么办呢？这个时候，就需要一个高效而可靠的消息中间件来进行通信。而RocketMQ就是其中之一。 什么是RocketMQ？RocketMQ是一个开源的分布式消息中间件，它最初由阿里巴巴集团开发并开源。它提供了高可靠性、高吞吐量、低延迟的分布式消息发布/订阅系统，广泛用于企业级分布式架构中。 怎么使用？首先，您需要在代码中引入RocketMQ的Java客户端。接下来，您需要使用Producer对象来发送消息，或者使用Consumer对象来接收消息。 发送消息12345678910// 对象实例化DefaultMQProducer producer = new DefaultMQProducer(&quot;Group Name&quot;);producer.setNamesrvAddr(&quot;IP Address:Port&quot;);producer.start();// 创建消息实例Message message = new Message(&quot;Topic Name&quot;,&quot;Tag Name&quot;,&quot;Message Body&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET));// 发送消息SendResult result = producer.send(message);// 关闭生产端实例producer.shutdown(); 接收消息1234567891011// 创建消费者实例DefaultMQConsumer consumer = new DefaultMQConsumer(&quot;Group Name&quot;);consumer.setNamesrvAddr(&quot;IP Address:Port&quot;);consumer.subscribe(&quot;Topic Name&quot;,&quot;Tag Name&quot;);consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -&gt; { for(MessageExt message:msgs){ System.out.println(new String(message.getBody())); }});// 启动消费者实例consumer.start(); 最后RocketMQ是一个强大的消息中间件，可帮助您实现高效、可靠的信息交流。它易于使用，广泛应用于企业级架构中。如果您需要处理大量数据、高并发请求等情况，RocketMQ值得考虑。","link":"/2020060162876/"},{"title":"kafka实践","text":"Kafka实践及代码示例简介Apache Kafka是一款实时数据流处理中心，可以快速高效地处理大规模、高吞吐量的数据流，由LinkedIn于2011年开发，后于2012年成为了Apache基金会的一个顶级开源项目。 Kafka以分布式消息队列的形式提供了高可靠（容错性高，支持数据冗余备份）、高伸缩性（支持多节点、多分区）、高吞吐率和低延迟的特性，适用于构建实时数据流的处理方案，被广泛应用于互联网、金融、电商等领域。 本文将介绍如何使用Java代码进行Kafka实践，包括Kafka配置、消息的生产者和消费者的实现。 环境搭建首先，需要搭建Kafka运行环境，具体步骤请参考Kafka官方文档。 Kafka配置Kafka的配置文件位于config/server.properties，可以根据需要进行修改。 以下是常用的配置项及其含义： broker.id：Broker的唯一标识符，具有唯一性； listeners：Broker监听的网络地址； advertised.listeners：供客户端访问的Broker地址； num.network.threads：处理网络请求的线程数； num.io.threads：处理磁盘IO的线程数； socket.send.buffer.bytes：发送数据缓冲区大小； socket.receive.buffer.bytes：接收数据缓冲区大小； socket.request.max.bytes：最大请求大小； num.partitions：每个Topic的分区数； log.dirs：Topic数据存储路径； auto.create.topics.enable：是否允许自动创建Topic； delete.topic.enable：是否允许删除Topic； group.initial.rebalance.delay.ms：Consumer组初始负载均衡延迟时间； offsets.topic.replication.factor：偏移量Topic的副本因子。 Kafka生产者Kafka生产者用于向指定的Topic中发送消息，Java代码示例如下： 1234567891011121314151617181920212223242526import org.apache.kafka.clients.producer.*;import java.util.Properties;public class KafkaProducerDemo { private static final String TOPIC_NAME = &quot;test_topic&quot;; private static final String BOOTSTRAP_SERVERS = &quot;localhost:9092&quot;; public static void main(String[] args) { Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, BOOTSTRAP_SERVERS); props.put(&quot;acks&quot;, &quot;all&quot;); props.put(&quot;retries&quot;, 0); props.put(&quot;batch.size&quot;, 16384); props.put(&quot;linger.ms&quot;, 1); props.put(&quot;buffer.memory&quot;, 33554432); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); for (int i = 0; i &lt; 10; i++) { String message = &quot;Message &quot; + i; producer.send(new ProducerRecord&lt;&gt;(TOPIC_NAME, message)); System.out.println(&quot;Sent:&quot; + message); } producer.close(); }} 以上代码实现了一个简单的Kafka生产者，可以向指定的TOPIC_NAME中发送10条消息。具体参数配置说明如下： bootstrap.servers：Kafka集群地址； acks：消息确认模式； 0：不等待Broker的任何确认； 1：等待Broker确认消息已写入本地磁盘； all：等待Broker确认消息已写入所有ISR副本； retries：消息发送失败后的重试次数； batch.size：消息批处理大小，单位为字节； linger.ms：延迟发送消息的时间，单位为毫秒； buffer.memory：生产者可用的内存缓存大小，单位为字节； key.serializer：序列化消息键的方式； value.serializer：序列化消息值的方式。 Kafka消费者Kafka消费者用于从指定的Topic中消费消息，Java代码示例如下： 123456789101112131415161718192021222324252627282930import org.apache.kafka.clients.consumer.*;import java.time.Duration;import java.util.Collections;import java.util.Properties;public class KafkaConsumerDemo { private static final String TOPIC_NAME = &quot;test_topic&quot;; private static final String BOOTSTRAP_SERVERS = &quot;localhost:9092&quot;; private static final String GROUP_ID = &quot;test_group&quot;; public static void main(String[] args) { Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, BOOTSTRAP_SERVERS); props.put(&quot;group.id&quot;, GROUP_ID); props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Collections.singletonList(TOPIC_NAME)); while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.printf(&quot;Received message: value = %s, topic = %s, partition = %d, offset = %d%n&quot;, record.value(), record.topic(), record.partition(), record.offset()); } consumer.commitAsync(); } }} 以上代码实现了一个简单的Kafka消费者，可以从指定的TOPIC_NAME中消费消息。具体参数配置说明如下： bootstrap.servers：Kafka集群地址； group.id：消费者组的唯一标识符； enable.auto.commit：是否开启自动提交偏移量； auto.commit.interval.ms：自动提交偏移量的时间间隔，单位为毫秒； key.deserializer：消息键的反序列化方式； value.deserializer：消息值的反序列化方式。 总结Kafka是一款高可靠、高伸缩性、高吞吐率和低延迟的分布式消息队列，广泛应用于互联网、金融、电商等领域。本文介绍了Kafka的基本概念及其Java代码实践，希望对读者有所帮助。","link":"/2020090162876/"},{"title":"nio的实践","text":"Java NIO 实践Java NIO（New IO）是Java SE1.4后新的IO API。NIO提供了与传统的IO API（Java IO）相比，更快速，更灵活的IO操作。 NIO与IO的差异IO的缺陷IO的读写是阻塞操作，即在读写数据的过程中，线程会被一直阻塞，无法进行其他操作。因此，IO的吞吐量受限，无法支持高并发的情况。 NIO的优点NIO使用了非阻塞IO来提高系统的IO性能。非阻塞IO的特点是在读写数据时，线程不会一直被阻塞，而是可以进行其他操作。这样，你可以使用一个线程来处理多个IO连接，提高了系统的吞吐量。 NIO的另一个优点是它的IO操作是面向缓冲区的。这就意味着数据是从缓冲区读取和写入的，而不是一个字节一个字节的读写。这减少了内存的拷贝次数，从而提高了系统的IO性能。 NIO的核心组件缓冲区 Buffer在NIO中，所有的数据都是从缓冲区读取或写入的。Buffer是一个字节数组或其他基本类型数组的容器。 Buffer的主要属性有： capacity: 缓冲区的容量 position: 下一个要读或写的位置 limit: 缓冲区的限制 mark: 缓冲区的标记 Buffer的常用类型有：ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。 通道 Channel在NIO中，所有的IO操作都是通过通道(Channel)来完成的。通道是一个双向的数据传输通道，可以完成读和写的操作。 通道的主要实现类有：FileChannel、DatagramChannel、SocketChannel和ServerSocketChannel。 选择器 SelectorSelector是NIO的多路复用器，它可以监控多个通道的IO事件，例如连接、读取和写入事件，使得一个线程可以同时处理多个IO连接。 NIO的实践在本次实践中，将使用NIO实现一个简单的服务端和客户端通信的功能。 服务端服务端的功能是监听客户端的请求，并返回当前系统时间给客户端。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class NIOServer { public static void main(String[] args) throws IOException { // 打开ServerSocketChannel ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 绑定到指定端口 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); // 配置为非阻塞模式 serverSocketChannel.configureBlocking(false); // 创建一个Selector Selector selector = Selector.open(); // 将ServerSocketChannel注册到Selector，并监听连接事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { // 阻塞等待IO事件 selector.select(); // 获取所有发生的IO事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); // 将已处理的事件移除 iterator.remove(); if (key.isAcceptable()) { // 有新连接事件 ServerSocketChannel channel = (ServerSocketChannel) key.channel(); // 获取SocketChannel通道 SocketChannel socketChannel = channel.accept(); // 配置为非阻塞模式 socketChannel.configureBlocking(false); // 将SocketChannel注册到Selector，并监听读取事件 socketChannel.register(selector, SelectionKey.OP_READ); } else if (key.isReadable()) { // 有可读事件 SocketChannel socketChannel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); // 读取数据到缓冲区 socketChannel.read(buffer); buffer.flip();// 切换为读取模式 byte[] bytes = buffer.array(); String request = new String(bytes).trim(); System.out.printf(&quot;request: %s\\n&quot;, request); // 处理请求 byte[] responseBytes = new Date().toString().getBytes(); ByteBuffer responseBuffer = ByteBuffer.wrap(responseBytes); // 返回响应数据 socketChannel.write(responseBuffer); } } } }} 客户端客户端的功能是连接服务端，并向服务端发送请求，获取服务器返回的时间信息。 12345678910111213141516171819202122232425public class NIOClient { public static void main(String[] args) throws IOException { SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(&quot;localhost&quot;, 8080)); socketChannel.configureBlocking(false); ByteBuffer buffer = ByteBuffer.wrap(&quot;Hello, server!&quot;.getBytes()); // 向服务端发送请求 socketChannel.write(buffer); System.out.println(&quot;Send request to server success.&quot;); ByteBuffer responseBuffer = ByteBuffer.allocate(1024); // 读取服务端的响应数据 socketChannel.read(responseBuffer); responseBuffer.flip();// 切换为读取模式 byte[] bytes = responseBuffer.array(); String response = new String(bytes).trim(); System.out.println(&quot;Server response: &quot; + response); socketChannel.close(); }} 总结通过这次实践，我们学会了如何使用Java NIO实现一个简单的服务端和客户端通信的功能。NIO的非阻塞IO模式和多路复用机制使得它能够支持更高效的IO操作，适用于高并发的系统场景。","link":"/2020110162876/"},{"title":"nio的入门","text":"Java NIO 入门指南Java NIO (Non-blocking I/O) 是 Java 平台中的一种 I/O 模型，允许使用非阻塞 I/O 方式进行高效的 I/O 操作。与传统的 I/O 模型相比，Java NIO 提供了更加底层的控制，更灵活的选择器和更高效的缓冲区管理，从而实现更高效的 I/O 操作。 Java NIO 的核心组件Java NIO 的核心组件包括以下几个部分： 缓冲区 (Buffer): NIO 中的所有 I/O 操作都通过缓冲区进行，缓冲区是对数据对象的封装。 通道 (Channel): NIO 中数据的读写操作是通过通道进行的，和传统的流不同，通道是可以双向的。 选择器 (Selector): 选择器是用于检测通道是否准备好读或写的 I/O 操作。多个通道可以注册到同一个选择器中，因此只需要一个线程就可以处理多个通道。 NIO 缓冲区在 NIO 中所有数据的读写操作都是通过缓冲区来完成的。缓冲区有以下几种类型： ByteBuffer: 字节缓冲区 CharBuffer: 字符缓冲区 ShortBuffer: 短整型缓冲区 IntBuffer: 整型缓冲区 LongBuffer: 长整型缓冲区 FloatBuffer: 浮点型缓冲区 DoubleBuffer: 双精度型缓冲区 创建缓冲区在 NIO 中缓冲区的创建一般有两种方式： 12345// 创建一个 ByteBuffer 缓冲区，默认容量为 1024 字节ByteBuffer buffer = ByteBuffer.allocate(1024);// 创建一个 ByteBuffer 缓冲区，容量为 1024 字节，限制为 512 字节ByteBuffer buffer2 = ByteBuffer.allocate(1024).limit(512); 缓冲区的属性在 NIO 中缓冲区的属性有以下几种： Capacity: 缓冲区的容量 Position: 缓冲区当前的位置，下一个要读或写的位置 Limit: 缓冲区的限制，不能读写超过这个位置 Mark: 缓冲区的标记，用于记录当前位置 缓冲区的读写操作在 NIO 中缓冲区的读写操作都是通过方法来实现的，常见的操作有： 1234567// 写入数据到缓冲区buffer.put((byte) 1);buffer.putInt(10);// 从缓冲区读取数据byte b = buffer.get();int i = buffer.getInt(); 缓冲区的切换和复制缓冲区之间的切换和复制是非常常见的操作，可以使用以下方法实现： 1234567891011121314151617// 切换到读模式buffer.flip();// 切换到写模式buffer.clear();// 切换到读模式并标记当前位置buffer.mark();// 重置到标记位置buffer.reset();// 复制原缓冲区buffer.copy();// 复制子缓冲区buffer.slice(); NIO 通道在 NIO 中数据的读写操作都是通过通道来完成的。通道是一个双向的数据通路，可以以单独的 I/O 操作来读取和写入数据。 创建通道在 NIO 中可以通过以下几种方式来创建通道： 1234567891011// 创建一个文件输入通道FileChannel inChannel = new FileInputStream(&quot;path/to/file&quot;).getChannel();// 创建一个文件输出通道FileChannel outChannel = new FileOutputStream(&quot;path/to/file&quot;).getChannel();// 创建一个网络输入通道SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(&quot;127.0.0.1&quot;, 8080));// 创建一个网络输出通道SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(&quot;127.0.0.1&quot;, 8080)); 通道的读写操作在 NIO 中数据的读写操作都是通过通道来完成的，通道的读写操作一般使用缓冲区来进行： 123456// 写入数据到通道channel.write(ByteBuffer.wrap(&quot;Hello, World!&quot;.getBytes()));// 从通道读取数据ByteBuffer buffer = ByteBuffer.allocate(1024);int bytesRead = channel.read(buffer); 通道的类型在 NIO 中通道的类型分为以下几种： FileChannel: 文件通道，用于读写文件数据 DatagramChannel: 数据报通道，用于 UDP 连接 SocketChannel: 套接字通道，用于 TCP 连接 ServerSocketChannel: 服务套接字通道，用于监听客户端连接 NIO 选择器在 NIO 中选择器是用于检测通道是否准备好读或写的 I/O 操作。选择器允许将多个通道注册到同一个选择器中，同一个线程就可以同时处理多个通道的 I/O 操作，从而提高 I/O 操作的效率。 创建选择器在 NIO 中可以通过以下方法来创建选择器： 1Selector selector = Selector.open(); 注册通道在 NIO 中可以通过以下方法将通道注册到选择器中： 1channel.register(selector, SelectionKey.OP_READ); 选择器的工作方式选择器一般使用循环来进行工作： 12345678910111213// 阻塞等待一个或多个通道准备好读或写int select = selector.select();// 获取选择器中已经准备好的通道Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();for (SelectionKey key : selectedKeys) { if (key.isReadable()) { // 处理通道的读操作 } else if (key.isWritable()) { // 处理通道的写操作 }} 总结Java NIO 提供了底层的 I/O 操作，允许使用非阻塞的方式进行高效的数据读写。熟练掌握 Java NIO 可以大大提高代码的性能和效率，建议对 Java NIO 进行深入学习并应用到实际项目中。","link":"/2020110162876/"},{"title":"rocketmq架构","text":"架构图 组件说明NameServerNameServer是RocketMQ Broker的路由信息注册中心。它将各个Broker的Cluster信息、Topic信息、路由信息等存储在内存中，提供查询服务给Producer和Consumer。 BrokerBroker是RocketMQ系统的核心组件，它是负责消息的存储、传输和处理的服务。每个Broker都包含了Message Store、消息队列、消费队列和消息处理线程。 ProducerProducer是消息的发送端，向某个Topic发送消息，消息将由NameServer查询到对应的Broker，然后通过网络传输到Broker。Producer将数据源封装成消息后发送给Broker。 ConsumerConsumer是消息的接收端，向Broker订阅某个Topic，消费消费队列中的消息。消息处理完成后，Consumer同步向Broker发送消息确认信息。 Java代码示例Producer1234567891011121314151617181920212223public class RocketMQProducer { public static void main(String[] args) throws MQClientException { // 创建生产者实例 DefaultMQProducer producer = new DefaultMQProducer(&quot;group&quot;); // 指定NameServer地址 producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); // 启动生产者 producer.start(); try { // 创建消息实例 Message message = new Message(&quot;topic&quot;, &quot;tag&quot;, &quot;Hello RocketMQ&quot;.getBytes()); // 发送消息 SendResult result = producer.send(message); System.out.println(result); } catch (Exception e) { e.printStackTrace(); } finally { // 关闭生产者 producer.shutdown(); } }} Consumer1234567891011121314151617181920public class RocketMQConsumer { public static void main(String[] args) throws MQClientException { // 创建消费者实例 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;group&quot;); // 指定NameServer地址 consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); // 订阅Topic和Tag consumer.subscribe(&quot;topic&quot;, &quot;tag&quot;); // 注册消息监听器 consumer.registerMessageListener((List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) -&gt; { // 处理消息 for (MessageExt msg : msgs) { System.out.println(new String(msg.getBody())); } return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; }); // 启动消费者 consumer.start(); }}","link":"/2020071162876/"},{"title":"rocketmq使用","text":"RocketMQ消息中间件使用技巧作为一名Java程序员，RocketMQ消息中间件是必不可少的工具之一。今天，我们就一起探讨一下如何更好地使用RocketMQ。 一、学习MQ基本概念首先，我们要先理解MQ的基本概念，包括Topic、Producer、Consumer、Message等。这些概念不仅在RocketMQ中适用，在其他消息中间件中也是普遍存在的。 二、选择合适的数据结构当我们在使用RocketMQ的时候，要注意选择合适的数据结构。消息中间件需要支持高并发和高吞吐量，因此在选择数据结构的时候，要有选择性。一般来说，ConcurrentHashMap和ConcurrentSkipListMap是不错的选择，它们不仅支持高并发，还可以保证数据的有序性。 三、合理规划Topic和Tag在使用RocketMQ时，Topic和Tag是非常重要的，要合理规划。一般来说，一个Topic下的Tag数量不要过多，否则会影响消费效率。同时，在定义Topic名称时，最好使用英文单词，而不要使用中文拼音，因为中文拼音在网络传输中容易出错。 四、掌握消息发送机制在使用RocketMQ的时候，消息发送机制是非常重要的。一般来说，同步发送和异步发送都是非常常见的方式，但是在使用异步发送时，要注意回调函数的使用。同时，在设置发送方式的时候，也要注意设置超时时间。 五、使用批量发送功能当我们需要发送大量消息时，使用批量发送功能可以大大提高发送的效率。使用批量发送功能时，要注意消息大小和数量的限制。 六、定期清理过期消息在使用RocketMQ时，要注意定期清理过期消息。如果消息一直积压在队列中，会对队列的性能造成影响。一般来说，我们可以使用定时任务，定期清理过期消息。 七、掌握消息消费机制在使用RocketMQ时，消息消费机制也是非常重要的。一般来说，我们可以使用单线程消费和多线程消费。在使用多线程消费时，要注意具体的消费方式，如广播和集群消费。 八、配置合适的参数在使用RocketMQ时，配置合适的参数也是非常重要的。我们可以根据实际情况，设置队列大小、文件数量、内存大小等参数。同时，在使用RocketMQ时，也要注意JVM参数的配置。 以上就是关于RocketMQ消息中间件的使用技巧介绍。希望大家在使用RocketMQ的时候，能够更加得心应手！","link":"/2020071862876/"},{"title":"rocketmq避坑","text":"RocketMQ消息中间件的避坑指南 RocketMQ是一个高性能、高可靠、可扩展的分布式消息中间件。在使用过程中，我们可能会遇到一些坑，本篇文章将为大家指出其中一些，并提供相应的解决方案。 1. 错误的Producer Group在发送消息时，我们需要使用Producer将消息发送到RocketMQ中。在创建Producer时，我们需要指定一个Producer Group，用于标识一组具有相同功能的Producer。如果我们使用了相同的Producer Group发送不同类型的消息，就会造成消息丢失或混淆的问题。因此，我们需要为每种类型的消息创建不同的Producer Group。 123456// 正确的示例DefaultMQProducer productA = new DefaultMQProducer(&quot;productA&quot;);DefaultMQProducer productB = new DefaultMQProducer(&quot;productB&quot;);// 错误的示例DefaultMQProducer product = new DefaultMQProducer(&quot;product&quot;); 2. 误用同步消息发送RocketMQ支持两种方式发送消息：同步和异步。在使用同步方式发送消息时，我们需要等待消息被成功写入CommitLog后再返回，否则将会抛出异常。如果我们在生产环境中误用同步方式发送大量消息，可能会导致生产者线程被阻塞，从而降低了整个系统的性能。 1234567891011// 正确的示例producer.send(message, new SendCallback(){ @Override public void onSuccess(SendResult sendResult) {} @Override public void onException(Throwable throwable) {}});// 错误的示例producer.send(message); 3. 消息体过大RocketMQ默认设置了消息大小限制，最大限制为4MB。如果我们发送的消息超过了限制，将会导致消息发送失败。因此，在发送消息前，我们需要确保消息体大小不会超过限制。 12345// 正确的示例，限制消息体大小为1MBmessage.setBody(new byte[1024 * 1024]);// 错误的示例，消息体大小超过了限制message.setBody(new byte[1024 * 1024 * 5]); 4. 错误的Consumer Group在RocketMQ中，一个消费者组可以包含多个消费者实例。当我们创建一个消费者组时，我们需要确保该组名称的唯一性，否则将会出现消费者实例互相抢占消息的问题。 123456// 正确的示例DefaultMQPushConsumer consumerA = new DefaultMQPushConsumer(&quot;consumerA&quot;, false);DefaultMQPushConsumer consumerB = new DefaultMQPushConsumer(&quot;consumerB&quot;, false);// 错误的示例DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;consumerA&quot;, false); 5. 误用顺序消息RocketMQ支持顺序消息，可以确保相同MessageQueue上的消息顺序消费。但是，在使用顺序消息时，我们需要保证消息发送与消费的时序完全一致。否则，将会导致消费者收到的消息顺序与生产者发送的顺序不一致，从而出现数据错误。 12345// 正确的示例messageQueueSelector.select(queueList, message, orderKey);// 错误的示例messageQueueSelector.select(queueList, message); 结语以上是本文介绍的RocketMQ消息中间件的避坑指南。希望能对大家在使用RocketMQ时避免一些坑有所帮助。记住，正确使用RocketMQ，才能发挥其优异的性能和可靠性！","link":"/2020080162876/"},{"title":"Rocketmq vs Kafka","text":"RocketMQ vs. Kafka简介RocketMQ和Kafka都是一种高性能的分布式消息系统。RocketMQ是Apache基金会的顶级项目，而Kafka则是由LinkedIn开发的Apache顶级项目。 RocketMQ和Kafka的目的都是处理大量数据量的分布式消息传输，用于解决分布式系统中的通信问题。 RocketMQ着重于可靠和快速消息传输，提供更好的消息存储、更强的容错机制，以及优秀的事务支持。而Kafka更注重于高可扩展性和可整合性，支持多种消费模式，如发布/订阅、队列、流、复制等。 架构RocketMQ基于压缩、排序和索引实现高效的消息存储和搜索，在消息存储格式、存储方式、索引方式方面进行了深度优化，从而达到高性能的要求。 Kafka的一个特点是，数据写入后不会被立即删除，而是由Kafka进行数据存储和维护。Kafka实现了高效的存储机制，通过预取机制，实现了高速批量消息处理。 性能RocketMQ是一个高度可靠和高性能的消息系统。因为RocketMQ使用主从模式进行高可用性和故障转移，所以在消息传递方面具有很高的可靠性。此外，RocketMQ通过固定的消息格式实现了高效的消息压缩、排序和索引，减小了系统消耗的带宽和磁盘空间。 Kafka通过高度优化的存储机制和基于批处理的处理机制，实现了高效、高稳定的消息传输。它支持高吞吐量和分区分裂，因此非常适合大数据量的传输。 吞吐量RocketMQ的吞吐量取决于硬盘的每秒钟IO速度，确保了可靠性的前提下，保持了高吞吐量。 Kafka在相对较高的吞吐量方面表现的更好，因为它可以支持更高的分区数量和分区分裂。 消费模式RocketMQ支持广播和负责任分布式消费模式。你可以选择多个消费节点以相同或者不同的组ID订阅相同的消息，RocketMQ将自动保证每个消息只被一个消费者消费。此外，RocketMQ的事务消息支持一阶段和两阶段支持。 Kafka支持发布/订阅、队列和流消费模式。在被消费者订阅时，消息是被分发到任意集群成员的。 结论那么，我们应该何时选择RocketMQ，何时选择Kafka呢？如果你的应用程序需要保证高吞吐量、可靠性和顺序访问，那么RocketMQ可能更适合。如果你需要一个高度可扩展和灵活的不严格要求顺序访问的消息队列，那么Kafka可能更适合。 好啦，今天我们就这样结束啦。希望本文能对堆糖吃货们有所帮助。如果你有任何问题或者疑问，欢迎在评论区留言哦！ 我们下期再见。","link":"/2020081962876/"},{"title":"zookeeper落地实践","text":"Kafka落地实践前言Kafka是一个分布式的消息队列系统，常用于解决大规模数据处理、实时数据传输等问题。在本文中，我们将介绍在Java语言中如何使用Kafka实现消息的发布和订阅。 环境准备在使用Kafka前，我们需要准备以下环境： JDK 1.8及以上版本 Kafka 2.4.1及以上版本 Kafka相关依赖包 快速入门创建Topic在Kafka中，我们需要先创建一个Topic（主题）来存储消息。可以使用Kafka提供的脚本工具创建Topic，命令如下： 1$ kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test 以上命令将会在Kafka中创建一个名为test的Topic，副本因子为1，分区数为1。 Producer消息的发送者称为Producer。在Java语言中，我们可以使用Kafka提供的KafkaProducer类来创建一个Producer实例。示例代码如下： 12345678910111213141516171819202122232425262728293031import java.util.Properties;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerRecord; public class ProducerExample { public static void main(String[] args) { // Producer配置信息 Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); props.put(&quot;acks&quot;, &quot;all&quot;); props.put(&quot;retries&quot;, 0); props.put(&quot;batch.size&quot;, 16384); props.put(&quot;linger.ms&quot;, 1); props.put(&quot;buffer.memory&quot;, 33554432); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); // 创建Producer实例 KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;&gt;(props); // 发送消息 for (int i = 0; i &lt; 10; i++) { String msg = &quot;消息 &quot; + i; ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;&gt;(&quot;test&quot;, msg); kafkaProducer.send(producerRecord); } // 关闭Producer实例 kafkaProducer.close(); }} 以上代码创建了一个Producer实例，并发送了10条字符串消息到名为test的Topic中。其中，配置信息中的属性可根据实际需求进行调整。 Consumer消息的消费者称为Consumer。在Java语言中，我们可以使用Kafka提供的KafkaConsumer类来创建一个Consumer实例。示例代码如下： 12345678910111213141516171819202122232425262728293031import java.util.Collections;import java.util.Properties;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.ConsumerConfig;import org.apache.kafka.clients.consumer.KafkaConsumer; public class ConsumerExample { public static void main(String[] args) { // Consumer配置信息 Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); props.put(&quot;group.id&quot;, &quot;test-group&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); // 创建Consumer实例 KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;&gt;(props); // 订阅Topic kafkaConsumer.subscribe(Collections.singletonList(&quot;test&quot;)); // 消费消息 while (true) { ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100); records.forEach(record -&gt; { System.out.printf(&quot;消费者：%s, 分区：%d, 偏移：%d, 消息：%s%n&quot;, record.key(), record.partition(), record.offset(), record.value()); }); } }} 以上代码创建了一个Consumer实例，并订阅了名为test的Topic。在消费消息时，我们使用了一个无限循环，在每次循环中调用了KafkaConsumer的poll方法从Topic中拉取最新的消息。 总结以上便是使用Java语言实现Kafka落地实践的简单示例，通过这些代码，我们可以了解到Kafka的基本使用方法。当然，在实际项目中，Kafka的应用远比我们在这篇文章中介绍的要复杂，因此需要根据实际业务需求进行详细的配置和应用。","link":"/2018010162876/"},{"title":"kafka学习技巧","text":"Kafka 学习技巧1. 简介Kafka 是由 LinkedIn 开源的一个分布式的、高吞吐量的消息队列系统。其主要特性包括： 支持数据的持久化存储，可以用于日志的存储和处理。 支持发布/订阅模式，多个消费者可以同时订阅同一个主题。 支持流处理，数据可以在 Kafka 中进行处理和流转，实现实时处理。 可以水平扩展，可以通过增加节点来扩展 Kafka 集群的吞吐量。 本文将介绍 Kafka 的一些学习技巧，帮助读者更好地掌握 Kafka 的使用。 2. 学习建议2.1 掌握基本概念在学习 Kafka 之前，需要先掌握以下基本概念： 生产者（Producer）：负责向 Kafka 发送消息的客户端。 消费者（Consumer）：从 Kafka 中订阅消息并处理这些消息的客户端。 主题（Topic）：是 Kafka 中消息的分类，可以理解为一个消息队列。 分区（Partition）：每个主题可以被分成多个分区，每个分区对应一个消息队列。 消息（Message）：是 Kafka 中的基本单位，是由 key、value、timestamp 和其他一些自定义属性组成的。 2.2 注意配置参数在使用 Kafka 时，需要注意一些配置参数，例如： bootstrap.servers：指定 Kafka 集群中的 Broker 的地址列表。 acks：指定生产者要求 Broker 在响应之前接收到的消息个数。 retries：指定在发送失败时 Producer 重试的最大次数。 需要根据实际情况灵活配置这些参数，以达到最优的性能和可靠性。 2.3 使用 API 编程Kafka 支持多种编程语言的 API，其中 Java API 是最常用的，且文档和示例都非常详细。通过编写简单的程序，可以快速掌握 Kafka 的基本使用方式和 API 的基本操作。 2.4 实践中学习最好的学习方法是实践中学习。可以使用 Docker 等工具快速搭建 Kafka 环境，然后通过编写简单的程序实践 Kafka 的基本操作，例如发送和接收消息，以及使用分区满足可伸缩性需求等。 3. 代码示例以下是通过 Java API 发送和接收消息的代码示例： 3.1 生产者发送消息123456789101112131415161718192021222324252627282930313233343536373839404142import org.apache.kafka.clients.producer.*;import java.util.Properties;public class ProducerExample { private static final String TOPIC_NAME = &quot;test-topic&quot;; private static final String BOOTSTRAP_SERVERS = &quot;localhost:9092&quot;; // Kafka 集群的 Broker 地址 public static void main(String[] args) { // 配置 Producer Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, BOOTSTRAP_SERVERS); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); // 创建 Producer 实例 Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); // 发送消息 for (int i = 0; i &lt; 10; i++) { ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(TOPIC_NAME, &quot;key-&quot; + i, &quot;value-&quot; + i); producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { if (exception != null) { exception.printStackTrace(); } else { System.out.printf(&quot;Sent message to topic=%s, partition=%d, offset=%d%n&quot;, metadata.topic(), metadata.partition(), metadata.offset()); } } }); } // 关闭 Producer producer.close(); }} 3.2 消费者接收消息12345678910111213141516171819202122232425262728293031323334353637import org.apache.kafka.clients.consumer.ConsumerRecords;;import org.apache.kafka.clients.consumer.KafkaConsumer;;import java.util.Collections;import java.util.Properties;public class ConsumerExample { private static final String TOPIC_NAME = &quot;test-topic&quot;; private static final String BOOTSTRAP_SERVERS = &quot;localhost:9092&quot;; // Kafka 集群的 Broker 地址 public static void main(String[] args) { // 配置 Consumer Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, BOOTSTRAP_SERVERS); props.put(&quot;group.id&quot;, &quot;test-group&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); // 创建 Consumer 实例 KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); // 订阅主题 consumer.subscribe(Collections.singletonList(TOPIC_NAME)); // 接收消息 while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000); records.forEach(record -&gt; { System.out.printf(&quot;Received message from topic=%s, partition=%d, offset=%d, key=%s, value=%s%n&quot;, record.topic(), record.partition(), record.offset(), record.key(), record.value()); }); } }} 4. 总结Kafka 是一个功能强大的消息队列系统，其概念和 API 非常丰富和灵活，但是也有一些需要注意的地方。通过掌握基本概念和配置参数，使用 API 编程，以及在实践中不断尝试，可以帮助读者更好地掌握 Kafka 的使用。","link":"/2018010162876/"},{"title":"zookeeper核心概念","text":"Kafka核心概念详解Kafka是一个分布式的、可扩展的、可重复消费的消息系统。它主要用于构建具有高可扩展性、高吞吐量的数据管道，用于实时数据提取、转换和流式处理。 在本文中，我们将对Kafka的核心概念进行详解，包括Topic、Partition、Broker、Producer、Consumer等。 TopicTopic是Kafka消息的逻辑容器，类似于传统消息队列中的主题。所有生产者发送的消息都归属于一个特定的Topic，所有消费者订阅的消息都来自于一个或多个Topic。Topic负责对消息进行分类、打标签，起到对消息进行归纳、分类的作用。 Kafka的Topic是具有多副本的分区日志，即每个Topic可以分为多个分区，每个分区都是一个有序的、不可变的消息序列，在分布式的Kafka集群中分布在不同的Broker上，实现了高可扩展性和可用性。 PartitionPartition是Kafka中的分区，它是Kafka进行消息存储的最小单位。一个Topic可以划分为多个Partition，每个Partition都是有序的消息序列，每个消息只会存在于单个Partition中。Partition和Topic是多对一的关系，即一个Topic可以包含多个Partition，每个Partition只属于一个Topic。 Partition的主要作用有如下几个： 满足高吞吐量：通过增加Partition的数量，可以提高Kafka的吞吐量，因为每个Partition都可以对应一个独立的消费者。如果每个消费者只消费一个Partition的话，那么每个消费者都可以独立的消费消息，不会受到其他Partition的影响，从而提高了Kafka的吞吐量。 支持水平扩展：通过将不同Partition分布在不同Broker上，可以实现水平扩展，提高可用性。 实现数据持久化：Kafka将消息存储在不同的Partition中，实现数据的持久化，保证数据不丢失。 BrokerBroker是Kafka集群中的基本单元，Kafka中每个节点都是一个Broker，它负责存储和处理消息。Broker是Kafka实现分布式的基础，通过Broker的负载均衡和故障转移，实现了Kafka的高可用性和可扩展性。 Broker之间通过Zookeeper协调，实现状态的同步和Leader的选举。每个Broker都有一个唯一的Broker ID，用来标识该Broker在Kafka集群中的唯一性。 ProducerProducer是Kafka中发送消息的客户端，它能够将消息发送到指定的Topic中。Producer发送消息的时候，可以指定消息的Key和Value，Key用于确定消息在Partition中的位置，Value是消息的主体。通过为消息设置Key，可以将相关的消息发送到同一个Partition中，从而保证消息的有序性和可靠性。 Producer发送消息的方式有同步和异步两种方式。同步方式下，产生消息后需要等待Broker的响应后才会继续执行。异步方式下，产生消息后会立即返回，不需要等待Broker的响应。 ConsumerConsumer是Kafka中接收消息的客户端，它能够从指定的Topic中消费消息。Consumer订阅了一个或多个Topic，通过不断轮询获取新的消息进行消费。Consumer可以单线程或多线程进行消息的消费，从而实现高吞吐量。 Kafka中的Consumer是具有高度灵活性的，可以根据需求进行灵活的消费方式，包括定期轮询、长轮询、阻塞+回调等多种方式，可以满足不同场景下的需求。 ConclusionKafka是一个高性能、分布式、可扩展的消息系统，它的核心概念包括Topic、Partition、Broker、Producer、Consumer等。熟悉这些核心概念可以帮助我们更好的理解Kafka的设计和使用方式，从而为数据处理和分析提供更好的支持。","link":"/2018010162876/"},{"title":"初识zookeeper","text":"zookeeper被用在了哪里? hbase: 在hbase中, zookeeper用于选举一个集群内的主节点, 以便跟踪可以的服务器, 并保存集群的元数据. kafka: 在kafka中, 用于检测崩溃, 实现topic的发现, 并保持主题的生产和消费状态 solr: 使用zookeeper来存储集群的元数据, 并协作更新这些元数据. 分布式系统需要注意的问题 消息延时: 可能因为网络拥堵, 这种任意延迟可能会导致不可预期的后果. 比如: 根据基准时钟, 进程p先发送一个消息后, 之后另一进程q发送了消息, 但是q也许会先完成传送. 处理器性能: 操作系统的调度和超载也可能会导致消息处理的任意延迟. 当一个进程想另一个进程发送消息的时候, 整个消息的延时时间约等于发送端消耗的时间, 传输时间, 接收端的处理时间的总和. 如果发送或接收过程需要调度时间进行处理, 消息延时会更高. 时钟偏移: 使用时间概念的系统并不少见, 比如, 确定某一时间系统中发生了哪些事件. 处理器时钟并不可靠, 它们之间也会发生任意的偏移. 因此, 依赖处理器时钟也许会导致错误的决策. 主-从模式的系统, 我们必须要解决以下3个关键问题: 主节点崩溃: 如果主节点发送错误并失效, 系统就无法分配新的任务或重新分配已失败的任务 从节点崩溃: 如果从节点崩溃, 已分配的任务将无法完成 通信故障: 如果主节点和从节点之间无法进行信息交换, 从节点将无法得知新任务分配给它. 我们可以得出主从架构的主要需求: 主节点选举 崩溃检测 组成员关系管理 元数据管理","link":"/2020090241723/"},{"title":"英语","text":"Je vais bien apprendre Français et ensuite aller en Afrique pour jeter un coup d’œil.","link":"/2021070216e5a472/"},{"title":"2023年","text":"2023-03ChatGPT的浪潮有点凶, 让我兴奋, 期待, 焦虑和紧张. 我预测未来ChatGPT应用的思路应该是: ChatGPT+需要聊天陪护的场景 GPT生成式预训练模型+特定业务操作场景 诞生MaaS模型即服务的商业软件公司 2023-04","link":"/20230328fa88ee57/"},{"title":"如何学习法语","text":"Je vais bien apprendre Français et ensuite aller en Afrique pour jeter un coup d’œil.","link":"/2022070216e5a472/"},{"title":"2018年","text":"2018The most boring thing.加班！加班！加班！ The most interesting thing. 周六加班 周日加班 节假日加班 365天天加班 Experiences of 2018温水煮青蛙 Expectations for 2019跳出去瞜两眼","link":"/20181225fa88ee57/"},{"title":"2019年","text":"湘江夕阳, 拍摄于湘江边. 2019Experiences计划永远赶不上变化 (PS: 值得庆幸的是, 疫情爆发之际, 我刚好离开武汉不久, 真心希望疫情早日结束!!!) Expectations for 2020脚踏实地，努力勤奋","link":"/20191230154a8569/"},{"title":"2020年","text":"2020 思绪万千做总结 春日同心战疫魔 盛夏相拥闻香气 秋雨窗前争闲事 寒风绵绵月朦胧 今年难忘处处情 欲说还休此话长 万语千言不可传 道路且长长相忆 (PS: 2020年终, 再一次希望疫情早日结束!!!)","link":"/202012296153aaf4/"},{"title":"2021年","text":"2021深知莫徘徊, 亦懂勿逗留2021总结词, 大写的迷茫","link":"/2021121026667/"},{"title":"2022年","text":"2022衣带渐宽终不悔…(PS: 2022末, 未阳, 疫情终于要走了!!!)","link":"/202212276153aaf4/"}],"tags":[{"name":"hello","slug":"hello","link":"/tags/hello/"},{"name":"make","slug":"make","link":"/tags/make/"},{"name":"product","slug":"product","link":"/tags/product/"},{"name":"project","slug":"project","link":"/tags/project/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"istioi","slug":"istioi","link":"/tags/istioi/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"java-src","slug":"java-src","link":"/tags/java-src/"},{"name":"java-juc","slug":"java-juc","link":"/tags/java-juc/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"rocketmq","slug":"rocketmq","link":"/tags/rocketmq/"},{"name":"java-nio","slug":"java-nio","link":"/tags/java-nio/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"英语","slug":"英语","link":"/tags/%E8%8B%B1%E8%AF%AD/"},{"name":"记录","slug":"记录","link":"/tags/%E8%AE%B0%E5%BD%95/"},{"name":"法语","slug":"法语","link":"/tags/%E6%B3%95%E8%AF%AD/"},{"name":"年终总结","slug":"年终总结","link":"/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"}],"categories":[{"name":"code","slug":"code","link":"/categories/code/"},{"name":"make","slug":"make","link":"/categories/make/"},{"name":"pm","slug":"pm","link":"/categories/pm/"},{"name":"code-java","slug":"code/code-java","link":"/categories/code/code-java/"},{"name":"pm-product","slug":"pm/pm-product","link":"/categories/pm/pm-product/"},{"name":"pm-project","slug":"pm/pm-project","link":"/categories/pm/pm-project/"},{"name":"code-golang","slug":"code/code-golang","link":"/categories/code/code-golang/"},{"name":"lang","slug":"lang","link":"/categories/lang/"},{"name":"且活且珍惜","slug":"且活且珍惜","link":"/categories/%E4%B8%94%E6%B4%BB%E4%B8%94%E7%8F%8D%E6%83%9C/"},{"name":"lang-en","slug":"lang/lang-en","link":"/categories/lang/lang-en/"},{"name":"记录","slug":"且活且珍惜/记录","link":"/categories/%E4%B8%94%E6%B4%BB%E4%B8%94%E7%8F%8D%E6%83%9C/%E8%AE%B0%E5%BD%95/"},{"name":"lang-fr","slug":"lang/lang-fr","link":"/categories/lang/lang-fr/"},{"name":"总结","slug":"且活且珍惜/总结","link":"/categories/%E4%B8%94%E6%B4%BB%E4%B8%94%E7%8F%8D%E6%83%9C/%E6%80%BB%E7%BB%93/"}]}